{"pageProps":{"site":{"domain":"jang-inspiration.com","name":"Jang. Inspiration","rootNotionPageId":"6246082f40144d0698ab59e9840b298a","rootNotionSpaceId":null,"description":"장영의 영감노트"},"recordMap":{"block":{"d4c292b6-9dff-423c-9922-75e83141ac3a":{"role":"reader","value":{"id":"d4c292b6-9dff-423c-9922-75e83141ac3a","version":573,"type":"page","properties":{"==~K":[["Yes"]],"AfoN":[["강화학습"]],"BN]P":[["Reinforcement Learning,Grid World,Dynamic Programming"]],"NVm^":[["reinforcement-learning-4"]],"a<ql":[["‣",[["d",{"type":"date","start_date":"2021-01-23"}]]]],"}nqi":[["Jay"]],"~]S<":[["강화학습에서의 다이내믹 프로그래밍의 정의에 대해 알아보고, 이를 기반으로 그리드 월드 예제 문제를 톺아보자."]],"title":[["<파이썬과 케라스로 배우는 강화학습> - (4) "],["그리드월드와 다이내믹 프로그래밍",[["b"]]]]},"content":["50eecb5b-f371-491a-89ab-daa1532a3604","3ae784ae-81dc-4b87-8f28-d9dda555efde","9f87eabe-e4d1-41d3-844c-ad353fbfe3c2","00d50577-2de0-4fc3-9841-2e4e03159c74","501f001a-8110-47e5-b716-173869f9bc5f","eb80b030-6dc1-457f-bf09-f4f6918ac2e8","df7c1910-f5b8-4cf5-a6b3-e27a217121cb","765c86d1-0305-4d0f-8103-561065bf6b61","64db500f-15ca-4c07-b27b-629e80c898be","fa38d816-e18c-433a-b87e-4d4653d0a759","9991c63f-da08-4da1-986f-a49678746f66","22519a78-aef8-4041-b8e8-902c540cd82e","d233d167-c11c-4c90-a36b-6c25c017d71c","3fc3eeb5-6fff-49f4-9047-8c722fa14f51","8fcd927e-c70e-4ca1-b9ff-37a92ed4f389","9d1c0933-a6dd-45c1-bea3-0d0ad61b3cac","82dc6081-2f9e-4bdf-829c-fcf8b7e0bcb9","5fdd8b5b-9a5b-498d-97ec-b8dc1518988f","7fddf341-ed18-4d14-ac23-5ce481193a8b","2b63f2af-49af-421b-8c80-5b9d4d83509c","6de16f79-fbfa-4076-a687-731c01bc3c3e","aa8c5e89-5508-41ac-9022-bb5871fffd7d","0052befd-4572-47a0-9472-dc0345ab88a6","503f78d2-987c-41f1-b057-d38b8d03a524","376f897a-7a6e-482d-aafa-36a616bc9b61","d0eda82c-aa1b-4f5d-a067-9bcd393000e8","809457d6-088c-46f6-9b80-c7e6169c5f54","b86624f3-99bd-4aff-9ecc-63fb4deb582d","6414f03e-6777-4eff-aa06-cf5140cd4c9f","8477c04d-dea4-434d-9343-519f8c303cfb","4432bfb7-8628-49de-a11c-e44a53afa506","0c47eeb0-620f-488f-a3ec-00922e9548f8","cdbf7e69-dfbc-4f8f-9f15-9c37085ad794","68a24579-e991-48e1-9dae-2d0681780081","d967310d-7496-4746-8f46-fb2606758478","f54e040e-e6a7-44a5-8da3-e023c461a64f","d89047c6-b1a5-473c-b36d-5f6d0fededd3","cfd74f5b-0d6c-4759-8bfa-a46a3bb73ff7","a16249ed-9529-4860-8851-3f491423b904","b1d3e139-3288-4652-9f53-b3c22d0d5771"],"format":{"page_icon":"🎮","page_cover":"https://images.unsplash.com/photo-1563209259-b2fa97148ce1?ixlib=rb-4.0.3&q=80&fm=jpg&crop=entropy&cs=tinysrgb","page_cover_position":0.5},"created_time":1676047458193,"last_edited_time":1677651625349,"parent_id":"ba8460cf-4781-486e-8976-01358ef4659d","parent_table":"collection","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"4f20ede8-ccf7-4ae1-82e5-819e100dd032":{"role":"reader","value":{"id":"4f20ede8-ccf7-4ae1-82e5-819e100dd032","version":129,"type":"collection_view","view_ids":["d91647c5-6a81-48b1-a1ff-a04529d0ddba","27bc73a3-5779-44e0-b617-2f0d26f5aa2f"],"collection_id":"ba8460cf-4781-486e-8976-01358ef4659d","format":{"collection_pointer":{"id":"ba8460cf-4781-486e-8976-01358ef4659d","table":"collection","spaceId":"4af10338-3e65-4b50-af9f-798d59d5c8f6"},"copied_from_pointer":{"id":"3e3073e9-7aee-481c-b831-765e112ec7b5","table":"block","spaceId":"fde5ac74-eea3-4527-8f00-4482710e1af3"}},"created_time":1675998770865,"last_edited_time":1677136438825,"parent_id":"6246082f-4014-4d06-98ab-59e9840b298a","parent_table":"block","alive":true,"copied_from":"3e3073e9-7aee-481c-b831-765e112ec7b5","created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"6246082f-4014-4d06-98ab-59e9840b298a":{"role":"reader","value":{"id":"6246082f-4014-4d06-98ab-59e9840b298a","version":609,"type":"page","properties":{"title":[["Jang. Inspiration"]]},"content":["651dcdf3-689d-42d2-8497-64f8509d3504","0bd6df0e-6679-499e-b382-c9dc2c597776","f4c89bb7-a90e-41d7-a678-588b3deff765","d5557a1e-de5e-4085-896d-362a19928b69","4f20ede8-ccf7-4ae1-82e5-819e100dd032","ce518f27-4e46-4e98-ac75-13c467c1370c","dfee9c57-3be6-41db-8113-a54eeef675a7","1109cf3f-d8f9-4532-a13e-1af177ad4fdd","5855fe5e-17e2-4f14-8b66-702838bcc734"],"format":{"page_icon":"https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b29e9b03-c79c-4e52-a45e-7228163ba524/compass-circular-tool_(3).png","page_cover":"/images/page-cover/nasa_reduced_gravity_walking_simulator.jpg","copied_from_pointer":{"id":"78754261-97cf-4616-9880-9def95960ebf","table":"block","spaceId":"fde5ac74-eea3-4527-8f00-4482710e1af3"},"page_cover_position":0.5},"permissions":[{"role":"editor","type":"user_permission","user_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb"},{"role":"reader","type":"public_permission","added_timestamp":1675998834095}],"created_time":1675998770872,"last_edited_time":1677392850666,"parent_id":"3a2d56c9-1da9-4a62-b698-f0ad3576c8c1","parent_table":"block","alive":true,"copied_from":"78754261-97cf-4616-9880-9def95960ebf","file_ids":["f70d3dc6-ce97-4be2-9cde-b86606147b41","a2bd3317-78e4-48bc-8d27-9b733175a416","7fae9664-8795-4723-844e-0adecdea62dc","4235c094-2110-4aa6-b058-6b5fe220dbb7","c8194a03-81d0-482d-a7de-f491a6e85f54","7eb95609-c81b-48c1-969e-5ef2f220bc5a","160057d8-120e-4f9f-8c1f-6bcf31a50f15","0cb9278b-708b-4da1-929a-6696aa8cdfa3","3eb9471e-9b71-4bd3-a13d-c33158a442be","b29e9b03-c79c-4e52-a45e-7228163ba524"],"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"50eecb5b-f371-491a-89ab-daa1532a3604":{"role":"reader","value":{"id":"50eecb5b-f371-491a-89ab-daa1532a3604","version":17,"type":"quote","properties":{"title":[["본 포스트는 “파이썬과 케라스로 배우는 강화학습” 도서의 네번째 리뷰 포스트입니다."]]},"created_time":1676047465640,"last_edited_time":1676055510495,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"3ae784ae-81dc-4b87-8f28-d9dda555efde":{"role":"reader","value":{"id":"3ae784ae-81dc-4b87-8f28-d9dda555efde","version":7,"type":"text","properties":{"title":[["http://www.yes24.com/Product/Goods/44136413",[["a","http://www.yes24.com/Product/Goods/44136413"]]]]},"created_time":1676055510770,"last_edited_time":1676055511055,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"9f87eabe-e4d1-41d3-844c-ad353fbfe3c2":{"role":"reader","value":{"id":"9f87eabe-e4d1-41d3-844c-ad353fbfe3c2","version":7,"type":"text","created_time":1676049250429,"last_edited_time":1676049250838,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"00d50577-2de0-4fc3-9841-2e4e03159c74":{"role":"reader","value":{"id":"00d50577-2de0-4fc3-9841-2e4e03159c74","version":4,"type":"table_of_contents","format":{"block_color":"gray"},"created_time":1676049257266,"last_edited_time":1676049257267,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"501f001a-8110-47e5-b716-173869f9bc5f":{"role":"reader","value":{"id":"501f001a-8110-47e5-b716-173869f9bc5f","version":4,"type":"text","created_time":1676049250429,"last_edited_time":1676049251318,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"eb80b030-6dc1-457f-bf09-f4f6918ac2e8":{"role":"reader","value":{"id":"eb80b030-6dc1-457f-bf09-f4f6918ac2e8","version":2,"type":"sub_header","properties":{"title":[["3장 강화학습 기초 2: 그리드월드와 다이내믹 프로그래밍",[["b"]]]]},"created_time":1676047465641,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"df7c1910-f5b8-4cf5-a6b3-e27a217121cb":{"role":"reader","value":{"id":"df7c1910-f5b8-4cf5-a6b3-e27a217121cb","version":2,"type":"divider","created_time":1676047465641,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"765c86d1-0305-4d0f-8103-561065bf6b61":{"role":"reader","value":{"id":"765c86d1-0305-4d0f-8103-561065bf6b61","version":2,"type":"text","properties":{"title":[["지금까지 열심히 강화학습 문제란 무엇인지, 문제를 어떻게 수학적으로 정의할 수 있는지, 그러한 문제의 최적의 방정식은 어떻게 구성되었는지를 살펴보았다. 이제 본격적으로 예제와 함께 문제를 풀어볼 시간이다 👉"]]},"created_time":1676047465641,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"64db500f-15ca-4c07-b27b-629e80c898be":{"role":"reader","value":{"id":"64db500f-15ca-4c07-b27b-629e80c898be","version":2,"type":"text","properties":{"title":[["다이내믹 프로그래밍(Dynamic Programming)",[["c"]]],["은 작은 문제가 큰 문제 안에 중첩되어 있는 경우, 작은 문제의 답을 다른 작은 문제에서 이용함으로써 효율적으로 계산하는 방법이다."]]},"created_time":1676047465641,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"fa38d816-e18c-433a-b87e-4d4653d0a759":{"role":"reader","value":{"id":"fa38d816-e18c-433a-b87e-4d4653d0a759","version":2,"type":"text","properties":{"title":[["다이내믹 프로그래밍을 이용하여,"]]},"created_time":1676047465641,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"9991c63f-da08-4da1-986f-a49678746f66":{"role":"reader","value":{"id":"9991c63f-da08-4da1-986f-a49678746f66","version":2,"type":"bulleted_list","properties":{"title":[["벨만 기대 방정식",[["b"]]],[" 을 푸는 것 –> "],["정책 이터레이션",[["c"]]]]},"created_time":1676047465642,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"22519a78-aef8-4041-b8e8-902c540cd82e":{"role":"reader","value":{"id":"22519a78-aef8-4041-b8e8-902c540cd82e","version":2,"type":"bulleted_list","properties":{"title":[["벨만 최적 방정식",[["b"]]],[" 을 푸는 것 –> "],["가치 이터레이션",[["c"]]]]},"created_time":1676047465642,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d233d167-c11c-4c90-a36b-6c25c017d71c":{"role":"reader","value":{"id":"d233d167-c11c-4c90-a36b-6c25c017d71c","version":2,"type":"text","properties":{"title":[["이며, 이번 장에서는 정책 이터레이션과 가치 이터레이션을 그리드월드 예제를 통해 코드로 실습해본다."]]},"created_time":1676047465642,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"3fc3eeb5-6fff-49f4-9047-8c722fa14f51":{"role":"reader","value":{"id":"3fc3eeb5-6fff-49f4-9047-8c722fa14f51","version":5,"type":"text","created_time":1676047614153,"last_edited_time":1676047614158,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"8fcd927e-c70e-4ca1-b9ff-37a92ed4f389":{"role":"reader","value":{"id":"8fcd927e-c70e-4ca1-b9ff-37a92ed4f389","version":2,"type":"quote","properties":{"title":[["다이내믹 프로그래밍은 이후에 강화학습의 근간이 되기 때문에 제대로 이해하는 것이 중요하다!!"]]},"created_time":1676047465642,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"9d1c0933-a6dd-45c1-bea3-0d0ad61b3cac":{"role":"reader","value":{"id":"9d1c0933-a6dd-45c1-bea3-0d0ad61b3cac","version":5,"type":"text","created_time":1676047615299,"last_edited_time":1676047615301,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"82dc6081-2f9e-4bdf-829c-fcf8b7e0bcb9":{"role":"reader","value":{"id":"82dc6081-2f9e-4bdf-829c-fcf8b7e0bcb9","version":2,"type":"sub_sub_header","properties":{"title":[["순차적 행동 결정 문제",[["b"]]]]},"created_time":1676047465642,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"5fdd8b5b-9a5b-498d-97ec-b8dc1518988f":{"role":"reader","value":{"id":"5fdd8b5b-9a5b-498d-97ec-b8dc1518988f","version":2,"type":"text","properties":{"title":[["강화학습",[["b"]]],[" 은 순차적으로 행동을 결정해야 하는 문제를 푸는 방법중 하나 이다. 2장에서 "],["MDP",[["b"]]],[" 를 정의하고 "],["벨만 방정식",[["b"]]],[" 을 세우는 과정을 다뤘다. 순차적 행동 결정 문제를 푸는 방법을 정리하면 아래와 같다."]]},"created_time":1676047465642,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"7fddf341-ed18-4d14-ac23-5ce481193a8b":{"role":"reader","value":{"id":"7fddf341-ed18-4d14-ac23-5ce481193a8b","version":2,"type":"numbered_list","properties":{"title":[["순차적 행동문제 –> MDP로 전환"]]},"created_time":1676047465642,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"2b63f2af-49af-421b-8c80-5b9d4d83509c":{"role":"reader","value":{"id":"2b63f2af-49af-421b-8c80-5b9d4d83509c","version":2,"type":"numbered_list","properties":{"title":[["가치함수를 벨만 방정식으로 반복적으로 계산"]]},"created_time":1676047465642,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"6de16f79-fbfa-4076-a687-731c01bc3c3e":{"role":"reader","value":{"id":"6de16f79-fbfa-4076-a687-731c01bc3c3e","version":2,"type":"numbered_list","properties":{"title":[["최적 가치함수와 최적 정책 도출"]]},"created_time":1676047465642,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"aa8c5e89-5508-41ac-9022-bb5871fffd7d":{"role":"reader","value":{"id":"aa8c5e89-5508-41ac-9022-bb5871fffd7d","version":15,"type":"text","properties":{"title":[["강화학습 또한 순차적 행동 결정 문제를 푸는 방법이기 때문에, 벨만 방정식을 이해해야 강화학습을 이해할 수 있다. 그렇다면 "],["벨만 방정식을 푼다는 것",[["b"]]],[" 은 어떤 의미일까? 보통 수학에서 "],["“방정식을 푼다”",[["b"]]],[" 라고 하면 "],["식을 만족하는 변수의 값을 찾는 것",[["b"]]],[" 을 말한다. 벨만 방정식을 통해 에이전트가 하고 싶은 것은 아래의 식을 만족하는 "],["⁍",[["e","v^*"]]],["을 찾는 것이다. 이 값을 찾는다면 벨만 방정식은 풀린 것이며 에이전트는 "],["최적 가치함수",[["c"]]],["를 알아낸 것이다."]]},"created_time":1676047465642,"last_edited_time":1676047641485,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"0052befd-4572-47a0-9472-dc0345ab88a6":{"role":"reader","value":{"id":"0052befd-4572-47a0-9472-dc0345ab88a6","version":13,"type":"equation","properties":{"title":[["v^*(s) = max_{a}E[R_{t+1} + \\gamma v^*(S_{t+1}) | S_t=s, A_t=a]"]]},"created_time":1676047626320,"last_edited_time":1676047679056,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"503f78d2-987c-41f1-b057-d38b8d03a524":{"role":"reader","value":{"id":"503f78d2-987c-41f1-b057-d38b8d03a524","version":2,"type":"sub_sub_header","properties":{"title":[["다이내믹 프로그래밍",[["b"]]]]},"created_time":1676047465642,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"376f897a-7a6e-482d-aafa-36a616bc9b61":{"role":"reader","value":{"id":"376f897a-7a6e-482d-aafa-36a616bc9b61","version":2,"type":"text","properties":{"title":[["다이내믹 프로그래밍의 기본적인 아이디어는 큰 문제 안에 작은 문제들이 중첩된 경우, 전체 큰 문제를 작은 문제로 쪼개서 풀겠다는 것이다. 이때 각각의 작은 문제들이 별개가 아니기 때문에 작은 문제들의 해답을 서로서로 이용할 수 있다. 이 특성을 이용하면 "],["결과적으로 계산량을 줄일 수 있다.",[["b"]]],[" (책에는 꽤 길게 서술되어 있는데 조금 생략했다)"]]},"created_time":1676047465643,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d0eda82c-aa1b-4f5d-a067-9bcd393000e8":{"role":"reader","value":{"id":"d0eda82c-aa1b-4f5d-a067-9bcd393000e8","version":5,"type":"text","properties":{"title":[["문제의 목표는 각 상태의 참 가치함수를 구하는 것이다. "]]},"created_time":1676047465643,"last_edited_time":1676047692767,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"809457d6-088c-46f6-9b80-c7e6169c5f54":{"role":"reader","value":{"id":"809457d6-088c-46f6-9b80-c7e6169c5f54","version":13,"type":"text","properties":{"title":[["즉, "],["⁍",[["e","v_\\pi (s_1), v_\\pi (s_2), v_\\pi (s_3) …"]]],["의 참값을 구하는 것이다. 이 큰 문제를 작은 문제로 나누어서 구하게 되면, 아래와 같이 풀 수 있다."]]},"created_time":1676047692761,"last_edited_time":1676047708726,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"b86624f3-99bd-4aff-9ecc-63fb4deb582d":{"role":"reader","value":{"id":"b86624f3-99bd-4aff-9ecc-63fb4deb582d","version":12,"type":"equation","properties":{"title":[["⁍",[["e","v_0(s) \\to v_1(s) \\to ... \\to v_k(s) \\to ... \\to v_\\pi (s)"]]]]},"created_time":1676047711969,"last_edited_time":1676047725194,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"6414f03e-6777-4eff-aa06-cf5140cd4c9f":{"role":"reader","value":{"id":"6414f03e-6777-4eff-aa06-cf5140cd4c9f","version":12,"type":"text","properties":{"title":[["한번의 화살표는 한 번의 계산으로서  "],["⁍",[["e","iteration = k"]]],["에서 "],["⁍",[["e","iteration=k+1"]]],["이 되는 과정이다. 이 계산은 모든 상태에 대해 진행하며 한번 계산이 끝나면 모든 상태의 가치함수를 업데이트한다. 다음 계산은 업데이트된 가치함수를 이용해 다시 똑같은 과정을 반복하는 것이다. 이런 식으로 계산하면 이전의 정보를 이용해 효율적으로 업데이트할 수 있게 된다."]]},"created_time":1676047465643,"last_edited_time":1676047750111,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"8477c04d-dea4-434d-9343-519f8c303cfb":{"role":"reader","value":{"id":"8477c04d-dea4-434d-9343-519f8c303cfb","version":5,"type":"text","created_time":1676047814272,"last_edited_time":1676047814274,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"4432bfb7-8628-49de-a11c-e44a53afa506":{"role":"reader","value":{"id":"4432bfb7-8628-49de-a11c-e44a53afa506","version":2,"type":"sub_sub_header","properties":{"title":[["격자로 이뤄진 간단한 예제: 그리드월드",[["b"]]]]},"created_time":1676047465643,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"0c47eeb0-620f-488f-a3ec-00922e9548f8":{"role":"reader","value":{"id":"0c47eeb0-620f-488f-a3ec-00922e9548f8","version":10,"type":"image","properties":{"source":[["https://longshiine.github.io/2021/01/23/Reinforcement-Learning-Basic-3/gridworld.png"]],"caption":[["그리드월드 예제"]]},"format":{"block_width":384,"block_full_width":false,"block_page_width":false},"created_time":1676047465643,"last_edited_time":1676047767120,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"cdbf7e69-dfbc-4f8f-9f15-9c37085ad794":{"role":"reader","value":{"id":"cdbf7e69-dfbc-4f8f-9f15-9c37085ad794","version":2,"type":"text","properties":{"title":[["예시로 우리가 풀어볼 문제는 다음과 같다. 빨간색 네모는 에이전트를 의미하고, 에이전트는 파란색 동그라미로 가야한다. 이때 (-1)의 보상을 주는 연두색 세모가 막고 있어, 세모를 피해서 네모에 도착해 (+1)의 보상을 받는 것이다. 파란색에 도착하는 "],["최적 정책",[["b"]]],[" 을 찾는 것이 우리의 목표다."]]},"created_time":1676047465644,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"68a24579-e991-48e1-9dae-2d0681780081":{"role":"reader","value":{"id":"68a24579-e991-48e1-9dae-2d0681780081","version":5,"type":"text","created_time":1676047786409,"last_edited_time":1676047786413,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d967310d-7496-4746-8f46-fb2606758478":{"role":"reader","value":{"id":"d967310d-7496-4746-8f46-fb2606758478","version":2,"type":"sub_sub_header","properties":{"title":[["강화학습 알고리즘의 흐름",[["b"]]]]},"created_time":1676047465644,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"f54e040e-e6a7-44a5-8da3-e023c461a64f":{"role":"reader","value":{"id":"f54e040e-e6a7-44a5-8da3-e023c461a64f","version":2,"type":"text","properties":{"title":[["MDP부터 강화학습의 기본적인 알고리즘까지 전반적인 흐름을 도식으로 보면 다음과 같다."]]},"created_time":1676047465644,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d89047c6-b1a5-473c-b36d-5f6d0fededd3":{"role":"reader","value":{"id":"d89047c6-b1a5-473c-b36d-5f6d0fededd3","version":6,"type":"image","properties":{"source":[["https://longshiine.github.io/2021/01/23/Reinforcement-Learning-Basic-3/RLflow.png"]],"caption":[["그리드월드 예제"]]},"format":{"block_width":336,"block_full_width":false,"block_page_width":false},"created_time":1676047465644,"last_edited_time":1676047784767,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"cfd74f5b-0d6c-4759-8bfa-a46a3bb73ff7":{"role":"reader","value":{"id":"cfd74f5b-0d6c-4759-8bfa-a46a3bb73ff7","version":4,"type":"text","created_time":1676047465644,"last_edited_time":1676047780161,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"a16249ed-9529-4860-8851-3f491423b904":{"role":"reader","value":{"id":"a16249ed-9529-4860-8851-3f491423b904","version":2,"type":"text","properties":{"title":[["자, 순차적 행동 결정 문제는 MDP를 통해 정의되었고, MDP로 정의되는 목표는 "],["에이전트가 받을 보상의 합을 최대",[["b"]]],[" 로 하는 것 이며, 이는 벨만 방정식을 품으로써 달성할 수 있다. 또한 벨만 방정식은 다이내믹 프로그래밍을 통해 풀 수 있으며, 다이내믹 프로그래밍에는 "],["정책 이터레이션(policy iteration)",[["c"]]],["과 "],["가치 이터레이션(value iteration)",[["c"]]],["이 있다. 이 두 방법은 후에 "],["살사(SARSA)",[["c"]]],["로 발전하며, 살사는 "],["큐러닝(Q-Learning)",[["c"]]],["으로 이어진다."]]},"created_time":1676047465644,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"b1d3e139-3288-4652-9f53-b3c22d0d5771":{"role":"reader","value":{"id":"b1d3e139-3288-4652-9f53-b3c22d0d5771","version":2,"type":"text","properties":{"title":[["이제 실제 코드를 통해 에이전트를 학습시켜보자!"]]},"created_time":1676047465644,"last_edited_time":1676047465650,"parent_id":"d4c292b6-9dff-423c-9922-75e83141ac3a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"3d335e41-f00a-45df-8432-34a266c7566a":{"role":"reader","value":{"id":"3d335e41-f00a-45df-8432-34a266c7566a","version":480,"type":"page","properties":{"title":[["About"]]},"content":["e1067486-5fb5-4dc3-9415-54abc63fc3a5","ab253a7b-1dec-4620-8c4e-e99f94e1f6c9","460c887f-cc3d-4351-8671-7cfbc6d3bc1d","c62b8a9d-e8cb-4c5b-be5a-48412e956c95","abe79af7-1342-438a-9a59-2d0b1ce59007","88d551b8-6b87-4540-89b9-3619a8fe4059","ae31ce74-317a-45ae-9dd3-16c14e764361","78f83c2a-05c2-4033-bcd8-945d700b2952","fd280029-9a4c-47fe-8e3c-ce8d3f146671","6a0d0c32-f1bc-4277-a128-33da8613ede4","2bcccf09-dccf-4896-8819-255cf75aabaf","d84b4bd5-3b6b-45dd-a807-5fea62c5213b","8b7fb4d3-0195-4f61-a0eb-330792f84053","e9394173-e197-4fad-a1db-ac74fdba3738","cb29948c-7258-4b05-9bfa-25bf19ad0946","a4e4243c-25aa-480d-a9ee-0af2230c7d76","172e2e25-e319-4766-ad38-02fc168994cd","6c428956-d84e-4855-a998-7a79f1fc8ea5","90f1cecf-6258-4b54-b0ee-26ee4d950872","3eec82e9-0211-4271-8c30-1dbc86ab3be1","8ce5f430-8c4c-4e8f-b6a4-23396731b27d","aeb9d85e-fffa-4c34-b253-cb0499f047a2","3d37f4c7-8064-4792-a863-234d8b4d05a6","77daa708-adbc-4092-b7f7-9e3c8a988049","26e3aca8-3e09-4a37-8c92-3c95cf579bbb"],"format":{"page_icon":"https://s3-us-west-2.amazonaws.com/secure.notion-static.com/fc853118-df50-43ed-96d9-0711493d5e25/jang_inspiration_logo.png","page_cover":"/images/page-cover/nasa_reduced_gravity_walking_simulator.jpg","copied_from_pointer":{"id":"f1199d37-579b-41cb-abfc-0b5174f4256a","table":"block","spaceId":"fde5ac74-eea3-4527-8f00-4482710e1af3"},"page_cover_position":0.5},"created_time":1675998770866,"last_edited_time":1677390731360,"parent_id":"d83b5165-627c-41b3-82f0-f1cbf904e176","parent_table":"block","alive":true,"copied_from":"f1199d37-579b-41cb-abfc-0b5174f4256a","file_ids":["c8028bee-f4c7-4736-8c36-fffcab5d977e","9407e769-d877-4de9-bbaa-9e5626d971ed","07d5a5b4-de2a-4322-bfcc-c4ade3a63b86","fc853118-df50-43ed-96d9-0711493d5e25"],"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d83b5165-627c-41b3-82f0-f1cbf904e176":{"role":"reader","value":{"id":"d83b5165-627c-41b3-82f0-f1cbf904e176","version":17,"type":"column","content":["e1fe2c9c-6eb8-412c-9874-a8ac2fce9ed8","3d335e41-f00a-45df-8432-34a266c7566a"],"format":{"column_ratio":0.25},"created_time":1676020529237,"last_edited_time":1676091451534,"parent_id":"1109cf3f-d8f9-4532-a13e-1af177ad4fdd","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"1109cf3f-d8f9-4532-a13e-1af177ad4fdd":{"role":"reader","value":{"id":"1109cf3f-d8f9-4532-a13e-1af177ad4fdd","version":13,"type":"column_list","content":["91ac285d-9a69-4ec4-96f6-9b046a15647c","028efbb4-417e-4742-8474-dd7a2ddeb8ee","d63c036c-b99a-4aa9-a068-87abc40d37a6","d83b5165-627c-41b3-82f0-f1cbf904e176"],"format":{"block_width":720,"block_full_width":false,"block_page_width":true},"created_time":1676020365844,"last_edited_time":1676091451534,"parent_id":"6246082f-4014-4d06-98ab-59e9840b298a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"e1067486-5fb5-4dc3-9415-54abc63fc3a5":{"role":"reader","value":{"id":"e1067486-5fb5-4dc3-9415-54abc63fc3a5","version":86,"type":"text","properties":{"title":[["Instagram",[["h","blue_background"],["a","https://www.instagram.com/jang.inspiration/"]]],[" • "],["GitHub",[["h","teal_background"],["a","https://github.com/longshiine"]]],[" • "],["LinkedIn",[["h","pink_background"],["a","https://www.linkedin.com/in/jangyeong-kim-b7924422a/"]]]]},"format":{"copied_from_pointer":{"id":"0ab4ae84-463a-4b31-9430-f4ed513c5fc2","table":"block","spaceId":"fde5ac74-eea3-4527-8f00-4482710e1af3"}},"created_time":1675998770872,"last_edited_time":1676960330564,"parent_id":"3d335e41-f00a-45df-8432-34a266c7566a","parent_table":"block","alive":true,"copied_from":"0ab4ae84-463a-4b31-9430-f4ed513c5fc2","created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}}},"collection":{"ba8460cf-4781-486e-8976-01358ef4659d":{"role":"reader","value":{"id":"ba8460cf-4781-486e-8976-01358ef4659d","version":117,"schema":{";KhU":{"name":"Last Updated","type":"last_edited_time"},"==~K":{"name":"Public","type":"checkbox"},"=bhc":{"name":"Curated","type":"checkbox"},"AfoN":{"name":"Category","type":"select","options":[{"id":"20579d4b-5ad0-469e-8946-2560e458bb81","color":"orange","value":"강화학습"},{"id":"b78b3694-0089-4efb-802c-c288e6190037","color":"green","value":"알고리즘"},{"id":"34c6aef1-b3b3-490e-9369-b5a385f7da4e","color":"blue","value":"딥러닝"},{"id":"67465999-8b72-4fe4-92ce-db5a812b880a","color":"brown","value":"공학수학"},{"id":"8b385c1c-8e95-4a02-b009-6215a718ebef","color":"pink","value":"글쓰기"},{"id":"435e1850-8e40-4b73-8496-0a3f694b6aeb","color":"purple","value":"스타트업"},{"id":"2b34c718-9490-4d2c-8c1d-949ea1a5010c","color":"gray","value":"독서"}]},"BN]P":{"name":"Tags","type":"multi_select","options":[{"id":"210cfb45-7eae-44e5-83dc-dba99aa3a853","color":"green","value":"Node.js"},{"id":"02b16a55-92ee-455d-9449-5e5e0a67cd04","color":"brown","value":"Computer Science"},{"id":"7993ec69-9767-4b84-adb9-5f1c907a6c77","color":"blue","value":"React.js"},{"id":"264c4a74-71d6-4015-bc91-5742970abd89","color":"yellow","value":"OSS"},{"id":"da38c5e1-f969-4abe-b28f-389b37aa22e5","color":"pink","value":"Startups"},{"id":"ceb7f269-10b7-49a9-bd4e-ba99533dee7b","color":"red","value":"Career"},{"id":"46b1d846-537f-43b5-a18c-298386278e63","color":"default","value":"Video"},{"id":"e485cc4c-e0de-4363-b442-22a0f6f588a9","color":"orange","value":"Saasify"},{"id":"5b6ee85e-ba0a-4c12-8e27-00e5b868939e","color":"gray","value":"SaaS"},{"id":"01c8627e-ae07-4f7b-b248-f877f88c8c4f","color":"purple","value":"Web Dev"},{"id":"136170f8-fe43-466b-b790-087508e8bc27","color":"blue","value":"Software Development"},{"id":"77f16ef0-4622-4f47-8f39-f5913a96421d","color":"pink","value":"Projects"},{"id":"aba9d5d2-c4f2-40ad-9f37-db6211536f92","color":"blue","value":"App Dev"},{"id":"84f76e57-8d2d-4078-bb7d-cf85520ba75c","color":"orange","value":"Lifestyle"},{"id":"38b5979d-877b-4cf4-920b-8b5da5ce9ba1","color":"yellow","value":"Thought Experiments"},{"id":"452e3943-dbcc-4d48-95fc-20d5d6339ddd","color":"orange","value":"Research"},{"id":"534e3ab2-fe89-487b-9784-71d76d5396a1","color":"purple","value":"Passion Economy"},{"id":"aa48c5a8-cfe3-4195-bfaa-25a72353299a","color":"yellow","value":"Tech"},{"id":"ff6898c4-f3f1-4024-b6a9-1cb871133744","color":"blue","value":"Creator Economy"},{"id":"ec59ba49-f2d4-4317-9a0e-3c7fb0bc60b8","color":"green","value":"Crypto"},{"id":"3fc961e4-4408-4d65-b750-7c136977ce61","color":"gray","value":"Deep Learning"},{"id":"a1419788-3341-407e-8df0-cd3d1f4ff636","color":"brown","value":"Gradient Vanishing"},{"id":"50ebe91f-e808-4056-b8ec-3b0bae45d464","color":"yellow","value":"Convolution Layer"},{"id":"ae8b3ff9-00e0-4d25-8d8d-e7389fc7fc8c","color":"orange","value":"Dot Product"},{"id":"8f6c2d82-17e0-4fb1-82eb-a6047ec75d02","color":"orange","value":"Vector"},{"id":"96ed8c32-a637-4b4f-ba99-3b397d04435a","color":"red","value":"Auction Theory"},{"id":"d4090af3-0dfb-480d-9503-0d0328774c16","color":"pink","value":"Reinforcement Learning"},{"id":"6fbb9d5c-c0f4-4791-8397-6e89c63e0c82","color":"yellow","value":"MDP"},{"id":"92885d4f-2302-43ac-87b0-e9e1c7a8cd8b","color":"yellow","value":"Introduction"},{"id":"f5ee4f74-bef9-4701-9d7d-1b9e7068d702","color":"blue","value":"Value Function"},{"id":"a575fa70-0999-44a3-b96c-262d57984b63","color":"green","value":"bellman equation"},{"id":"807f640e-1abc-476a-8300-1fe0ec0a15a3","color":"gray","value":"Grid World"},{"id":"e959edcb-aeb9-4a66-91e9-7677c68a85a8","color":"purple","value":"Dynamic Programming"},{"id":"3c5ba2f8-7ec5-4d9c-89b8-2ae975f4740a","color":"default","value":"Policy Iteration"},{"id":"b79852f3-5c3c-4de7-8d6d-731673caae40","color":"green","value":"Value Iteration"},{"id":"c2bd765b-351d-4a6d-a75d-94e8c476a180","color":"red","value":"Policy Evaluation"},{"id":"4a911c23-ca00-4f29-ad2f-463eb166f8f2","color":"brown","value":"SARSA"},{"id":"563d1a3e-095d-4ad8-bb7e-cc8c8195a9c1","color":"green","value":"Q-Learning"},{"id":"9e1bb3b2-a545-4e9d-b1eb-c47d2db8f4a8","color":"gray","value":"Writing"},{"id":"fcaf8148-917c-44bd-8ca1-fce87ba28f55","color":"blue","value":"Nepal"},{"id":"d93da022-471d-4d13-8dbc-051aa3e4639f","color":"orange","value":"Travel"},{"id":"f20c5e6f-58fe-4208-baa3-20704f665d21","color":"purple","value":"Algorithm"},{"id":"447d9963-8cfc-4c4c-9adb-88f0dc85f249","color":"red","value":"Python"},{"id":"633d7256-ffbf-4e5b-9912-906130d85250","color":"yellow","value":"Big-O"},{"id":"1a1af600-6b9b-4b8e-9483-c038712cda7c","color":"default","value":"String"},{"id":"b24d85c4-b7af-411c-905f-c9ae68eab612","color":"pink","value":"Array"},{"id":"87516a34-7662-4a77-a219-149777b960dc","color":"red","value":"LinkedList"},{"id":"d63330f6-ba17-4b9c-b370-579f4c99358a","color":"blue","value":"Stack"},{"id":"04eff27e-18a0-4883-8915-6ba26059106d","color":"yellow","value":"Queue"},{"id":"328cf039-a0b4-4b5c-90f7-be587808a1dc","color":"orange","value":"Deque"},{"id":"3364095f-3a21-47c6-8460-16ddc7f02c13","color":"brown","value":"HashTable"},{"id":"64841489-db5b-45ba-972a-7af2f53f41c7","color":"yellow","value":"Graph"},{"id":"b6dea43b-7633-4290-91f0-9761023838b0","color":"purple","value":"Tree"},{"id":"9dc575d0-d0d5-4282-8430-aae294857404","color":"gray","value":"Heap"},{"id":"edc331ab-bf6d-4985-9ecc-6884de83e8fc","color":"brown","value":"Trie"},{"id":"f2fdcca6-c69d-4b53-ab23-665ca7a223b9","color":"yellow","value":"Sort"},{"id":"5e02ca54-b743-4501-9776-62e030442114","color":"default","value":"BinarySearch"},{"id":"9a317b05-c2df-41ff-bf3f-32c39b5c451b","color":"red","value":"Greedy"},{"id":"536f3cec-7932-4444-b8c7-154672ad5fe6","color":"pink","value":"DivideAndConquer"},{"id":"1fe05376-d59a-4e4a-8596-fcd70f194621","color":"orange","value":"Basic"},{"id":"6fdde3f1-6554-4e54-ba5b-af1fc95b0ce4","color":"green","value":"Linear"},{"id":"28fc1aec-d1dd-44bb-a3ab-78ebc6f74837","color":"yellow","value":"NonLinear"},{"id":"e74e9521-68b1-4c11-ab42-a034a44dfd24","color":"blue","value":"알고리즘"},{"id":"42f167a6-7e2e-4d8e-854d-426689132f08","color":"brown","value":"Amazon"},{"id":"8aefb99d-7b6b-453b-941f-e114e32c6438","color":"blue","value":"book"},{"id":"d5083966-d1d3-4116-a615-5107104890c2","color":"pink","value":"Business"},{"id":"df607bdb-4379-4273-a45e-e52d436aef0d","color":"red","value":"Diffusion Model"},{"id":"da21253b-a1e7-4fe8-9ed3-6073a347c457","color":"orange","value":"Paper Review"}]},"NVm^":{"name":"Slug","type":"text"},"QSi`":{"name":"Series","type":"checkbox"},"a<ql":{"name":"Published","type":"date"},"jhf;":{"name":"Tweet","type":"text"},"nAX{":{"name":"Created","type":"created_time"},"}nqi":{"name":"Author","type":"text"},"~]S<":{"name":"Description","type":"text"},"title":{"name":"Name","type":"title"}},"format":{"copied_from_pointer":{"id":"e5fdcb8e-6e29-4bc9-828d-263749307808","table":"collection","spaceId":"fde5ac74-eea3-4527-8f00-4482710e1af3"},"property_visibility":[{"property":"AfoN","visibility":"hide_if_empty"},{"property":"BN]P","visibility":"hide_if_empty"},{"property":"a<ql","visibility":"hide_if_empty"},{"property":"}nqi","visibility":"hide_if_empty"},{"property":"~]S<","visibility":"hide"},{"property":"==~K","visibility":"hide"},{"property":"jhf;","visibility":"hide"},{"property":"=bhc","visibility":"hide"},{"property":"NVm^","visibility":"hide"},{"property":"nAX{","visibility":"hide"},{"property":";KhU","visibility":"hide"},{"property":"QSi`","visibility":"hide"}],"collection_page_properties":[{"visible":false,"property":"AfoN"},{"visible":true,"property":"BN]P"},{"visible":true,"property":"a<ql"},{"visible":false,"property":"}nqi"},{"visible":true,"property":"~]S<"},{"visible":true,"property":"==~K"},{"visible":true,"property":"jhf;"},{"visible":false,"property":"=bhc"},{"visible":false,"property":"NVm^"},{"visible":true,"property":"nAX{"},{"visible":false,"property":";KhU"}]},"parent_id":"4f20ede8-ccf7-4ae1-82e5-819e100dd032","parent_table":"block","alive":true,"copied_from":"e5fdcb8e-6e29-4bc9-828d-263749307808","template_pages":["cacb6437-50cd-4a3d-9d43-58962f75e40b"],"migrated":true,"space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6","deleted_schema":{":nQy":{"name":"Curating","type":"text"}}}}},"collection_view":{"d91647c5-6a81-48b1-a1ff-a04529d0ddba":{"role":"reader","value":{"id":"d91647c5-6a81-48b1-a1ff-a04529d0ddba","version":33,"type":"gallery","name":"Gallery view","format":{"gallery_cover":{"type":"page_cover"},"gallery_cover_size":"medium","gallery_properties":[{"visible":false,"property":"AfoN"},{"visible":false,"property":"jhf;"},{"visible":false,"property":"NVm^"},{"visible":false,"property":"==~K"},{"visible":false,"property":";KhU"},{"visible":false,"property":"=bhc"},{"visible":false,"property":"}nqi"},{"visible":false,"property":"nAX{"},{"visible":false,"property":"BN]P"},{"visible":true,"property":"title"},{"visible":true,"property":"~]S<"},{"visible":true,"property":"a<ql"}],"gallery_cover_aspect":"cover","hide_linked_collection_name":true,"inline_collection_first_load_limit":{"type":"load_limit","limit":10}},"parent_id":"4f20ede8-ccf7-4ae1-82e5-819e100dd032","parent_table":"block","alive":true,"page_sort":["e3df5b79-eb34-4bec-a82f-628699f43852","7a8e9c32-39af-4bca-a26e-3f8f1c9a1762","7864e0d8-d646-4df5-a4ae-057371b7559d","36a57bd6-d63a-40f0-a0a2-6ba247885fab","c2994f3d-696a-4015-b7d1-2b71883562ad","58fc3d75-92a2-44e9-ab0d-84cb61086232","30ac6075-b07c-41fa-b684-15c16f1134ba","4c804cac-3119-4cc3-a621-a82040d9a0db","6ce6c0ba-0d6f-40b3-b7d4-afe8ca715c73","64158711-b8f3-4c3d-ba2f-3999059c5581","0c679f04-0865-4142-a65b-28668aa9daea","54fa8c94-ead7-4b14-b068-174936adb37f","ab2e2675-7daf-464f-a2c4-563136630232","ef52bf7e-8726-4804-a0d5-e9b5f7919284","460f888e-b262-4f14-a39f-93ae0090bb9d","eff2e07b-ee44-45e0-b46a-622deb611d0b","c94f3f08-d65f-4f7d-a409-72c353f9786d","daac7673-f388-475e-8f43-a345dc350bef","6ff46924-9cc3-4445-badc-28e7daa5fa5a","c114dc9f-b09a-4e30-9c0d-5ace92e6a8e3","51b78f8b-69ff-4a46-9ec6-74f0d5400d3e","06adcb1d-3acf-4266-a8d9-6cb0d3c439ce","22c49483-380f-4b94-be90-b437b7cbab52","45a3d677-b3df-4cc1-ac40-7e0ab214aeef","7a177274-38ce-4f03-b3f6-06e20b0ba4f8","15aa9135-7cca-40c7-b656-ba4457524924","599373d0-99e2-4c28-89de-d273b43aca5c","48756e2f-e604-4421-9b34-be2c90e20589","b94b3e79-f161-45a8-bf8e-5315f85dca99","3e71fe2e-c827-4fc6-b610-7d71147ae4a7","298f8e1a-a9f2-4274-b5f1-7279f7bc4e5b","c7f629b2-6f4e-43fe-8720-4a3a10d4e651","b1fded7b-ceea-46d0-89e2-32010807d35c","bd99ffd5-ce6d-4418-be0e-6db2cd8ae070","5e852682-71e3-45b9-8056-d40e972563fd","1db23f4a-8d7e-4445-b241-a8e4be5bd02a","70df362d-5c3a-4d2c-a3da-ef27e1f207e3","dae737f3-5216-4c50-b708-2bf7c2662020","a13c9d7e-5e2f-44c3-bd8c-17fd50ca4892","f3236b1d-73c7-45d5-920e-f7cac8c19573","c181e327-c3bf-42f8-b8aa-21a367ce64f2","f5613c52-6b68-4073-b593-03d26f51e710"],"query2":{"sort":[{"property":"=bhc","direction":"descending"},{"property":"a<ql","direction":"descending"}],"filter":{"filters":[{"filters":[{"filter":{"value":{"type":"exact","value":true},"operator":"checkbox_is"},"property":"==~K"},{"filter":{"value":{"type":"exact","value":true},"operator":"checkbox_is"},"property":"=bhc"},{"filter":{"value":{"type":"exact","value":true},"operator":"checkbox_is"},"property":"QSi`"}],"operator":"and"}],"operator":"and"},"aggregations":[{"aggregator":"count"}]},"space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"27bc73a3-5779-44e0-b617-2f0d26f5aa2f":{"role":"reader","value":{"id":"27bc73a3-5779-44e0-b617-2f0d26f5aa2f","version":1,"type":"table","name":"","format":{"table_properties":[{"width":293,"visible":true,"property":"title"},{"width":398,"visible":true,"property":"~]S<"},{"width":81,"visible":true,"property":"==~K"},{"width":105,"visible":true,"property":"=bhc"},{"width":146,"visible":true,"property":"a<ql"},{"width":200,"visible":true,"property":"BN]P"},{"width":122,"visible":true,"property":"}nqi"},{"width":156,"visible":true,"property":"jhf;"},{"width":146,"visible":true,"property":"NVm^"},{"width":200,"visible":true,"property":";KhU"},{"width":200,"visible":false,"property":"nAX{"}]},"parent_id":"4f20ede8-ccf7-4ae1-82e5-819e100dd032","parent_table":"block","alive":true,"page_sort":["f3d44d4c-975d-4b11-8396-c68b35bfdb26","70df362d-5c3a-4d2c-a3da-ef27e1f207e3","f3236b1d-73c7-45d5-920e-f7cac8c19573","4117e62e-18ec-4503-a32a-6c31806a5e2a","6b9736df-63cb-4e7c-ba8e-d6e54f26d6c9","c2f261a2-c616-4198-b1a9-2caf6be162a0","a082287f-d4c9-4cfb-b3b2-72b8bbf043c6","4801bc76-a763-46a8-981d-79dc38c5d85a","e3df5b79-eb34-4bec-a82f-628699f43852","36a57bd6-d63a-40f0-a0a2-6ba247885fab","c2994f3d-696a-4015-b7d1-2b71883562ad","58fc3d75-92a2-44e9-ab0d-84cb61086232","30ac6075-b07c-41fa-b684-15c16f1134ba","4c804cac-3119-4cc3-a621-a82040d9a0db","6ce6c0ba-0d6f-40b3-b7d4-afe8ca715c73","64158711-b8f3-4c3d-ba2f-3999059c5581","0c679f04-0865-4142-a65b-28668aa9daea","54fa8c94-ead7-4b14-b068-174936adb37f","ab2e2675-7daf-464f-a2c4-563136630232","ef52bf7e-8726-4804-a0d5-e9b5f7919284","460f888e-b262-4f14-a39f-93ae0090bb9d","eff2e07b-ee44-45e0-b46a-622deb611d0b","c94f3f08-d65f-4f7d-a409-72c353f9786d","daac7673-f388-475e-8f43-a345dc350bef","6ff46924-9cc3-4445-badc-28e7daa5fa5a","c114dc9f-b09a-4e30-9c0d-5ace92e6a8e3","51b78f8b-69ff-4a46-9ec6-74f0d5400d3e","06adcb1d-3acf-4266-a8d9-6cb0d3c439ce","22c49483-380f-4b94-be90-b437b7cbab52","1db23f4a-8d7e-4445-b241-a8e4be5bd02a","dae737f3-5216-4c50-b708-2bf7c2662020","a13c9d7e-5e2f-44c3-bd8c-17fd50ca4892","7864e0d8-d646-4df5-a4ae-057371b7559d","7a8e9c32-39af-4bca-a26e-3f8f1c9a1762","0f58fdf7-da3e-4793-93f8-b2503443020d","ca43f24a-f6c2-4611-a92a-8051ec80fb0f","36b681a4-e13e-4a78-a2d6-f56b2e3657a1","8cfc0d5a-59ba-4ea0-9609-4720753d5fba","88891af2-1639-4eff-a2c9-f3ba6668b2ea","92db0a94-6e1e-44a6-8df5-882e60ff5b3f","0d958b63-df7a-44a4-b80c-5408c78f59e4","7a177274-38ce-4f03-b3f6-06e20b0ba4f8","ae0b3ee0-531c-4f81-8d4b-cc6dd040fea1","bf9953ee-2589-4969-948c-0d31106a9deb","fdb7d90f-a355-4e7d-8f9a-3d07a58a457e","561e9779-b56c-4310-8913-d54675e02c74","6951e99b-10cc-4833-a27f-f0e08f8941d0","76a4bb7d-be00-45f3-bbcd-cba28c38588b","18c92268-31e5-4509-8644-9c6ad9e44c10","6463af62-efa9-47dc-91ce-99df728f66e0"],"query2":{"sort":[{"property":"=bhc","direction":"descending"},{"property":"a<ql","direction":"descending"}],"aggregations":[{"property":"title","aggregator":"count"}]},"space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}}},"notion_user":{},"collection_query":{},"signed_urls":{},"preview_images":{"images.unsplash.com/photo-1563209259-b2fa97148ce1":{"originalWidth":4509,"originalHeight":3433,"dataURIBase64":"data:image/webp;base64,UklGRkQAAABXRUJQVlA4IDgAAAAQAgCdASoQAAwABUB8JZQCdAEN4Z4/0jgAAP7nI6g5q7g7NuXgHKw945x+RhNJbTW2vaRJ2E2wAA=="},"notion.so/image/notion.so%2Fimages%2Fpage-cover%2Fnasa_reduced_gravity_walking_simulator.jpg":{"originalWidth":2000,"originalHeight":1597,"dataURIBase64":"data:image/webp;base64,UklGRjwAAABXRUJQVlA4IDAAAADQAQCdASoQAA0ABUB8JaQAAuUwaXLIHAD+3O9cAAKxBQKBBYBng9tx6GTwHd24mAA="},"notion.so/image/s3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb29e9b03-c79c-4e52-a45e-7228163ba524%2Fcompass-circular-tool_(3).png":{"originalWidth":2000,"originalHeight":2000,"dataURIBase64":"data:image/webp;base64,UklGRv4AAABXRUJQVlA4WAoAAAAQAAAADwAADwAAQUxQSFUAAAARL6CmkRQ4eF5eaio0EBGB5+2AUWxbbR5t/yWkKiDsUwVQnn8xoViI6P8EAOK9AiCF/BQQSXKHsKrOmo21PddC4xsKsbafNSc1jfQLgBSSGsD0HBoAAFZQOCCCAAAAsAIAnQEqEAAQAAVAfCWkAA+DSIAfdDvk/UudpKAAAPYcuQdG3VZft4V447Ryb0FWml/BLapzhboSZ6SLFp2WFSojeqJNq2VAANIrwpK47u1M/geoV8ECX9+TEWBDeQC4c2g3HcSldGi6FylcOf6PWeqJaegO6jdPFlsvX04FC2gAAA=="},"notion.so/image/longshiine.github.io%2F2021%2F01%2F23%2FReinforcement-Learning-Basic-3%2Fgridworld.png":{"originalWidth":2000,"originalHeight":2281,"dataURIBase64":"data:image/webp;base64,UklGRj4AAABXRUJQVlA4IDIAAADQAQCdASoOABAABUB8JYwC7AEUo7WjAAD+18LfOyIKDW4hUhz1tQGY+OUAJst6RR/gAA=="},"notion.so/image/longshiine.github.io%2F2021%2F01%2F23%2FReinforcement-Learning-Basic-3%2FRLflow.png":{"originalWidth":2000,"originalHeight":2298,"dataURIBase64":"data:image/webp;base64,UklGRloAAABXRUJQVlA4IE4AAADwAQCdASoOABAABUB8JbACdAD0rv+5GtAA/vHgRUujc/FoQQV12FKiv90gx0mJ0zYcz/NSA23Cd9Yl/72U60/JEgcoDHvyIaSiPajwAAA="},"notion.so/image/s3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffc853118-df50-43ed-96d9-0711493d5e25%2Fjang_inspiration_logo.png":{"originalWidth":2000,"originalHeight":2000,"dataURIBase64":"data:image/webp;base64,UklGRv4AAABXRUJQVlA4WAoAAAAQAAAADwAADwAAQUxQSFUAAAARL6CmkRQ4eF5eaio0EBGB5+2AUWxbbR5t/yWkKiDsUwVQnn8xoViI6P8EAOK9AiCF/BQQSXKHsKrOmo21PddC4xsKsbafNSc1jfQLgBSSGsD0HBoAAFZQOCCCAAAAsAIAnQEqEAAQAAVAfCWkAA+DSIAfdDvk/UudpKAAAPYcuQdG3VZft4V447Ryb0FWml/BLapzhboSZ6SLFp2WFSojeqJNq2VAANIrwpK47u1M/geoV8ECX9+TEWBDeQC4c2g3HcSldGi6FylcOf6PWeqJaegO6jdPFlsvX04FC2gAAA=="}}},"pageId":"d4c292b6-9dff-423c-9922-75e83141ac3a","rawPageId":"reinforcement-learning-4"},"__N_SSG":true}
<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="robots" content="index,follow"/><meta property="og:type" content="website"/><meta property="og:site_name" content="Jang. Inspiration"/><meta property="twitter:domain" content="jang-inspiration.com"/><meta name="description" content="강화학습이란 무엇인지, 탄생한 배경부터 주로 사용하는 용어까지 살펴보자. 강화학습이 풀고자하는 문제는 무엇이며, 순차적 행동 결정 문제란 무엇인지 톺아보자."/><meta property="og:description" content="강화학습이란 무엇인지, 탄생한 배경부터 주로 사용하는 용어까지 살펴보자. 강화학습이 풀고자하는 문제는 무엇이며, 순차적 행동 결정 문제란 무엇인지 톺아보자."/><meta name="twitter:description" content="강화학습이란 무엇인지, 탄생한 배경부터 주로 사용하는 용어까지 살펴보자. 강화학습이 풀고자하는 문제는 무엇이며, 순차적 행동 결정 문제란 무엇인지 톺아보자."/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:image" content="https://jang-inspiration.com/api/social-image?id=3fd51011-fdfe-4366-931c-6ed584049b34"/><meta property="og:image" content="https://jang-inspiration.com/api/social-image?id=3fd51011-fdfe-4366-931c-6ed584049b34"/><link rel="canonical" href="https://jang-inspiration.com/reinforcement-learning-introduction"/><meta property="og:url" content="https://jang-inspiration.com/reinforcement-learning-introduction"/><meta property="twitter:url" content="https://jang-inspiration.com/reinforcement-learning-introduction"/><link rel="alternate" type="application/rss+xml" href="https://jang-inspiration.com/feed" title="Jang. Inspiration"/><meta property="og:title" content="&lt;파이썬과 케라스로 배우는 강화학습&gt; - (1) 강화학습 개요"/><meta name="twitter:title" content="&lt;파이썬과 케라스로 배우는 강화학습&gt; - (1) 강화학습 개요"/><title>&lt;파이썬과 케라스로 배우는 강화학습&gt; - (1) 강화학습 개요</title><meta name="naver-site-verification" content="3942485b5f7254d146b71f1249d907d89048a4d6"/><link rel="preload" as="image" href="https://images.unsplash.com/photo-1563209259-b2fa97148ce1?ixlib=rb-4.0.3&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb"/><meta name="next-head-count" content="22"/><link rel="shortcut icon" href="/favicon.ico"/><link rel="icon" type="image/png" sizes="32x32" href="favicon.png"/><link rel="manifest" href="/manifest.json"/><link rel="preload" href="/_next/static/css/d2e6a1cb5181bdcf.css" as="style"/><link rel="stylesheet" href="/_next/static/css/d2e6a1cb5181bdcf.css" data-n-g=""/><link rel="preload" href="/_next/static/css/4e32f0fa5eadbe4b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/4e32f0fa5eadbe4b.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script defer="" src="/_next/static/chunks/3607272e.d338bf53926ee7c2.js"></script><script defer="" src="/_next/static/chunks/853.526a4df21aef109c.js"></script><script src="/_next/static/chunks/webpack-bcbf8f4abc46b243.js" defer=""></script><script src="/_next/static/chunks/framework-4556c45dd113b893.js" defer=""></script><script src="/_next/static/chunks/main-f08b69bdcc7bbb61.js" defer=""></script><script src="/_next/static/chunks/pages/_app-27630c741ae01a08.js" defer=""></script><script src="/_next/static/chunks/780-d9c40783d635496e.js" defer=""></script><script src="/_next/static/chunks/634-d6e2e697c346745d.js" defer=""></script><script src="/_next/static/chunks/pages/%5BpageId%5D-35899cbd792aff57.js" defer=""></script><script src="/_next/static/I-ojLq_lc7g-_5LzXbOVe/_buildManifest.js" defer=""></script><script src="/_next/static/I-ojLq_lc7g-_5LzXbOVe/_ssgManifest.js" defer=""></script></head><body><script>
/** Inlined version of noflash.js from use-dark-mode */
;(function () {
  var storageKey = 'darkMode'
  var classNameDark = 'dark-mode'
  var classNameLight = 'light-mode'
  function setClassOnDocumentBody(darkMode) {
    document.body.classList.add(darkMode ? classNameDark : classNameLight)
    document.body.classList.remove(darkMode ? classNameLight : classNameDark)
  }
  var preferDarkQuery = '(prefers-color-scheme: dark)'
  var mql = window.matchMedia(preferDarkQuery)
  var supportsColorSchemeQuery = mql.media === preferDarkQuery
  var localStorageTheme = null
  try {
    localStorageTheme = localStorage.getItem(storageKey)
  } catch (err) {}
  var localStorageExists = localStorageTheme !== null
  if (localStorageExists) {
    localStorageTheme = JSON.parse(localStorageTheme)
  }
  // Determine the source of truth
  if (localStorageExists) {
    // source of truth from localStorage
    setClassOnDocumentBody(localStorageTheme)
  } else if (supportsColorSchemeQuery) {
    // source of truth from system
    setClassOnDocumentBody(mql.matches)
    localStorage.setItem(storageKey, mql.matches)
  } else {
    // source of truth from document.body
    var isDarkMode = document.body.classList.contains(classNameDark)
    localStorage.setItem(storageKey, JSON.stringify(isDarkMode))
  }
})();
</script><div id="__next"><div class="notion notion-app light-mode notion-block-3fd51011fdfe4366931c6ed584049b34"><div class="notion-viewport"></div><div class="notion-frame"><header class="notion-header"><div class="notion-nav-header"><div class="breadcrumbs"><a class="breadcrumb" href="/"><div class="notion-page-icon-inline notion-page-icon-image"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%272000%27%20height=%272000%27/%3e"/></span><img alt="Jang. Inspiration" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="icon notion-page-icon" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;background-size:cover;background-position:0% 0%;filter:blur(20px);background-image:url(&quot;data:image/webp;base64,UklGRv4AAABXRUJQVlA4WAoAAAAQAAAADwAADwAAQUxQSFUAAAARL6CmkRQ4eF5eaio0EBGB5+2AUWxbbR5t/yWkKiDsUwVQnn8xoViI6P8EAOK9AiCF/BQQSXKHsKrOmo21PddC4xsKsbafNSc1jfQLgBSSGsD0HBoAAFZQOCCCAAAAsAIAnQEqEAAQAAVAfCWkAA+DSIAfdDvk/UudpKAAAPYcuQdG3VZft4V447Ryb0FWml/BLapzhboSZ6SLFp2WFSojeqJNq2VAANIrwpK47u1M/geoV8ECX9+TEWBDeQC4c2g3HcSldGi6FylcOf6PWeqJaegO6jdPFlsvX04FC2gAAA==&quot;)"/><noscript><img alt="Jang. Inspiration" src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb29e9b03-c79c-4e52-a45e-7228163ba524%2Fcompass-circular-tool_(3).png?table=block&amp;id=6246082f-4014-4d06-98ab-59e9840b298a&amp;cache=v2" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="icon notion-page-icon" loading="lazy"/></noscript></span></div><span class="title">Jang. Inspiration</span></a></div><div class="notion-nav-header-rhs breadcrumbs"><a href="/about" class="breadcrumb button">About</a><div class="breadcrumb button styles_hidden__7gYve"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32" d="M256 48v48m0 320v48m147.08-355.08l-33.94 33.94M142.86 369.14l-33.94 33.94M464 256h-48m-320 0H48m355.08 147.08l-33.94-33.94M142.86 142.86l-33.94-33.94"></path><circle cx="256" cy="256" r="80" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32"></circle></svg></div><div role="button" class="breadcrumb button notion-search-button"><svg class="notion-icon searchIcon" viewBox="0 0 17 17"><path d="M6.78027 13.6729C8.24805 13.6729 9.60156 13.1982 10.709 12.4072L14.875 16.5732C15.0684 16.7666 15.3232 16.8633 15.5957 16.8633C16.167 16.8633 16.5713 16.4238 16.5713 15.8613C16.5713 15.5977 16.4834 15.3516 16.29 15.1582L12.1504 11.0098C13.0205 9.86719 13.5391 8.45215 13.5391 6.91406C13.5391 3.19629 10.498 0.155273 6.78027 0.155273C3.0625 0.155273 0.0214844 3.19629 0.0214844 6.91406C0.0214844 10.6318 3.0625 13.6729 6.78027 13.6729ZM6.78027 12.2139C3.87988 12.2139 1.48047 9.81445 1.48047 6.91406C1.48047 4.01367 3.87988 1.61426 6.78027 1.61426C9.68066 1.61426 12.0801 4.01367 12.0801 6.91406C12.0801 9.81445 9.68066 12.2139 6.78027 12.2139Z"></path></svg></div></div></div></header><div class="notion-page-scroller"><div class="notion-page-cover-wrapper"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%274509%27%20height=%273433%27/%3e"/></span><img alt="&lt;파이썬과 케라스로 배우는 강화학습&gt; - (1) 강화학습 개요" src="https://images.unsplash.com/photo-1563209259-b2fa97148ce1?ixlib=rb-4.0.3&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb" decoding="async" data-nimg="intrinsic" class="notion-page-cover" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-position:center 50%;background-size:cover;background-position:center 50%;filter:blur(20px);background-image:url(&quot;data:image/webp;base64,UklGRkQAAABXRUJQVlA4IDgAAAAQAgCdASoQAAwABUB8JZQCdAEN4Z4/0jgAAP7nI6g5q7g7NuXgHKw945x+RhNJbTW2vaRJ2E2wAA==&quot;)"/><noscript><img alt="&lt;파이썬과 케라스로 배우는 강화학습&gt; - (1) 강화학습 개요" src="https://images.unsplash.com/photo-1563209259-b2fa97148ce1?ixlib=rb-4.0.3&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-position:center 50%" class="notion-page-cover"/></noscript></span></div><main class="notion-page notion-page-has-cover notion-page-has-icon notion-page-has-text-icon notion-full-page"><div class="notion-page-icon-hero notion-page-icon-span"><span class="notion-page-icon" role="img" aria-label="🎮">🎮</span></div><h1 class="notion-title">&lt;파이썬과 케라스로 배우는 강화학습&gt; - (1) <b>강화학습 개요</b></h1><div class="notion-collection-page-properties"><div class="notion-collection-row"><div class="notion-collection-row-body"><div class="notion-collection-row-property"><div class="notion-collection-column-title"><svg viewBox="0 0 14 14" class="notion-collection-column-title-icon"><path d="M7 13A6 6 0 107 1a6 6 0 000 12zM3.751 5.323A.2.2 0 013.909 5h6.182a.2.2 0 01.158.323L7.158 9.297a.2.2 0 01-.316 0L3.751 5.323z"></path></svg><div class="notion-collection-column-title-body">Category</div></div><div class="notion-collection-row-value"><span class="notion-property notion-property-select"><div class="notion-property-select-item notion-item-orange">강화학습</div></span></div></div><div class="notion-collection-row-property"><div class="notion-collection-column-title"><svg viewBox="0 0 14 14" class="notion-collection-column-title-icon"><path d="M4 3a1 1 0 011-1h7a1 1 0 110 2H5a1 1 0 01-1-1zm0 4a1 1 0 011-1h7a1 1 0 110 2H5a1 1 0 01-1-1zm0 4a1 1 0 011-1h7a1 1 0 110 2H5a1 1 0 01-1-1zM2 4a1 1 0 110-2 1 1 0 010 2zm0 4a1 1 0 110-2 1 1 0 010 2zm0 4a1 1 0 110-2 1 1 0 010 2z"></path></svg><div class="notion-collection-column-title-body">Tags</div></div><div class="notion-collection-row-value"><span class="notion-property notion-property-multi_select"><div class="notion-property-multi_select-item notion-item-pink">Reinforcement Learning</div><div class="notion-property-multi_select-item notion-item-yellow">Introduction</div></span></div></div><div class="notion-collection-row-property"><div class="notion-collection-column-title"><svg viewBox="0 0 14 14" class="notion-collection-column-title-icon"><path d="M10.889 5.5H3.11v1.556h7.778V5.5zm1.555-4.444h-.777V0H10.11v1.056H3.89V0H2.333v1.056h-.777c-.864 0-1.548.7-1.548 1.555L0 12.5c0 .856.692 1.5 1.556 1.5h10.888C13.3 14 14 13.356 14 12.5V2.611c0-.855-.7-1.555-1.556-1.555zm0 11.444H1.556V3.944h10.888V12.5zM8.556 8.611H3.11v1.556h5.445V8.61z"></path></svg><div class="notion-collection-column-title-body">Published</div></div><div class="notion-collection-row-value"><span class="notion-property notion-property-date">January 19, 2021</span></div></div><div class="notion-collection-row-property"><div class="notion-collection-column-title"><svg viewBox="0 0 14 14" class="notion-collection-column-title-icon"><path d="M7 4.568a.5.5 0 00-.5-.5h-6a.5.5 0 00-.5.5v1.046a.5.5 0 00.5.5h6a.5.5 0 00.5-.5V4.568zM.5 1a.5.5 0 00-.5.5v1.045a.5.5 0 00.5.5h12a.5.5 0 00.5-.5V1.5a.5.5 0 00-.5-.5H.5zM0 8.682a.5.5 0 00.5.5h11a.5.5 0 00.5-.5V7.636a.5.5 0 00-.5-.5H.5a.5.5 0 00-.5.5v1.046zm0 3.068a.5.5 0 00.5.5h9a.5.5 0 00.5-.5v-1.045a.5.5 0 00-.5-.5h-9a.5.5 0 00-.5.5v1.045z"></path></svg><div class="notion-collection-column-title-body">Author</div></div><div class="notion-collection-row-value"><span class="notion-property notion-property-text"><b>Jay</b></span></div></div></div></div></div><div class="notion-page-content notion-page-content-has-aside"><article class="notion-page-content-inner"><blockquote class="notion-quote notion-block-c38ef64520544c65bbf8c44fe333fea4"><div>본 포스트는 “파이썬과 케라스로 배우는 강화학습” 도서의 첫번째 리뷰 포스트입니다.</div></blockquote><div class="notion-text notion-block-8e4b1731b7064f8bad023fb390a06614"><a target="_blank" rel="noopener noreferrer" class="notion-link" href="http://www.yes24.com/Product/Goods/44136413">http://www.yes24.com/Product/Goods/44136413</a></div><div class="notion-blank notion-block-5ea8d1d89ad049669485d027809e2efa"> </div><div class="notion-table-of-contents notion-gray notion-block-5285cf357f424eddb036b43f5a084dcc"><a href="#e2dbaad8773e472f982efdb2ea88a287" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:0">1장. 강화학습 개요</span></a><a href="#dda1262b9e9b4bd5b3d30813ba26b7ea" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">스키너의 강화 연구</span></a><a href="#4425c80730254e70929b5789f84e2dee" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">머신러닝과 강화학습</span></a><a href="#0ef4304d1fe7485d9d7ce7fbfbdf8ee6" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">스스로 학습하는 컴퓨터, 에이전트</span></a><a href="#716d3dd917f3488fa23c3a5a3974d201" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">강화학습의 장점</span></a><a href="#c314367d452840f3bb6096791b61b275" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">순차적 행동 결정 문제</span></a><a href="#a17764008d0848319b16d7f9fa37a5cf" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">순차적 행동 결정 문제의 구성요소</span></a><a href="#35b6ae3b16874901aa3473c1ff1a731a" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">강화학습의 예시: 브레이크 아웃</span></a><a href="#55841c0262f24a0584d88b5180a3908b" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">사람과 강화학습 에이전트의 차이</span></a><a href="#8768c63f941e4a109119522fc131793f" class="notion-table-of-contents-item"><span class="notion-table-of-contents-item-body" style="display:inline-block;margin-left:24px">1장 한줄평</span></a></div><div class="notion-blank notion-block-1ff4f58651604be79b0d40963e8d99d9"> </div><div class="notion-text notion-block-f2e00b57e8f7439e866a9d718b3b0973"><b>방학이 어느새 1달여가 다 되어가는 시점이다..</b> 😥</div><div class="notion-text notion-block-f1aa7fb89aa1407696f13d5784e013f4">1달간의 잉여생활을 청산하기 위해, 서점에 들러 강화학습 도서를 집었다. 원래는 CS234를 도전해보려 했으나, 미약한 영어실력 및 충전된 잉여력으로 인해 1강을 채 못 끝내었다는 불편한 진실..을 뒤로 하고, 코드와 함께 있는 이 도서를 정독해보기로 마음먹었다. 아무래도 나는 코드가 없으면 재미를 못느끼는 타입인가 보다. 암튼암튼. 이 책 만큼은 끝까지 도달하기를 진심진심으로 바란다. (교보문고에서 무려 2만 8천원을 고대로 내고 사왔다!)</div><div class="notion-blank notion-block-07c30a74c81d45a5a811b975d2a4d043"> </div><h3 class="notion-h notion-h2 notion-h-indent-0 notion-block-e2dbaad8773e472f982efdb2ea88a287" data-id="e2dbaad8773e472f982efdb2ea88a287"><span><div id="e2dbaad8773e472f982efdb2ea88a287" class="notion-header-anchor"></div><a class="notion-hash-link" href="#e2dbaad8773e472f982efdb2ea88a287" title="1장. 강화학습 개요"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>1장. 강화학습 개요</b></span></span></h3><hr class="notion-hr notion-block-aaa9d8621d8a46feaf682fac888e90ca"/><div class="notion-text notion-block-e477240351d94b6d84d858ec6c6bdc3b">이 책의 목표는 다음과 같다.</div><ul class="notion-list notion-list-disc notion-block-0b2c49b9c79b4019a964670e7c5cb1c4"><li>최소한의 수식과 직관적인 그림을 통해 강화학습을 이해하는 것</li></ul><ul class="notion-list notion-list-disc notion-block-1eb9408a429a48458f25b59f09674b75"><li>간단한 게임에 강화학습 이론을 직접 구현해보는 것</li></ul><div class="notion-text notion-block-211fc5064eba460589ba60b93077d8e2">행동심리학과 머신러닝에 뿌리를 둔 강화학습에 대해 공부하려면 강화학습이 풀려고 하는 문제에 대해 정의를 먼저 해야한다. 강화학습은 다른 머신러닝 분야와 다르게 <b>순차적으로 행동을 결정해야 하는 문제</b>를 다루며 이러한 문제를 컴퓨터가 풀기 위해서는 문제를 수학적으로 잘 정의해야 한다.</div><div class="notion-blank notion-block-e2f9aaa537804bbda10b2a4739f20bd5"> </div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-dda1262b9e9b4bd5b3d30813ba26b7ea" data-id="dda1262b9e9b4bd5b3d30813ba26b7ea"><span><div id="dda1262b9e9b4bd5b3d30813ba26b7ea" class="notion-header-anchor"></div><a class="notion-hash-link" href="#dda1262b9e9b4bd5b3d30813ba26b7ea" title="스키너의 강화 연구"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>스키너의 강화 연구</b></span></span></h4><div class="notion-text notion-block-64f6588785cd4e0f92a53d3467513b77">강화(Reinforcement)는 동물이 시행착오(Trial and Error)를 통해 학습하는 방법 중 하나이고, 행동심리학의 시행착오 학습이라는 개념은 동물들이 이것저것 시도해보면서 그 결과를 통해 학습하는 것을 말한다.</div><ol start="1" class="notion-list notion-list-numbered notion-block-3e22cf76d065434283e596ae6ded9298"><li>굶긴 쥐를 상자에 넣는다.</li></ol><ol start="2" class="notion-list notion-list-numbered notion-block-d2a28517b0a149cfb8a5a95c1e125e4c"><li>쥐는 돌아다니다가 우연히 상자 안에 있는 지렛대를 누르게 된다.</li></ol><ol start="3" class="notion-list notion-list-numbered notion-block-2bc1e9a56fef4a848b7398336b5201d8"><li>지렛대를 누르자 먹이가 나온다.</li></ol><ol start="4" class="notion-list notion-list-numbered notion-block-c79e22c3e92a4d739705a2cb33703864"><li>지렛대를 누르는 행동과 먹이와의 상관관계를 모르는 쥐는 다시 돌아다닌다.</li></ol><ol start="5" class="notion-list notion-list-numbered notion-block-cc70ccd5fcc34e8db37ab7e9a5cee9af"><li>그러다가 우연히 쥐가 다시 지렛대를 누르면 쥐는 이제 먹이와 지렛대 사이의 관계를 알게 되고 점점 지렛대를 자주 누르게 된다.</li></ol><ol start="6" class="notion-list notion-list-numbered notion-block-cd6126d3fdce428e8af96bdb118e741d"><li>이 과정을 반복하면서 쥐는 지렛대를 누르면 먹이를 먹을 수 있다는 것을 학습한다.</li></ol><div class="notion-text notion-block-fe3b4aa7262d4bef9e78f045c2b7730c">즉, 강화라는 것은 동물이 이전에 배우지 않았지만 직접 시도하면서 행동과 그 결과로 나타나는 좋은 보상사이의 상관관계를 학습하는 것이다</div><div class="notion-blank notion-block-8373d2207c5e40718d00456778d37354"> </div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-4425c80730254e70929b5789f84e2dee" data-id="4425c80730254e70929b5789f84e2dee"><span><div id="4425c80730254e70929b5789f84e2dee" class="notion-header-anchor"></div><a class="notion-hash-link" href="#4425c80730254e70929b5789f84e2dee" title="머신러닝과 강화학습"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>머신러닝과 강화학습</b></span></span></h4><div class="notion-text notion-block-d32ec99994734d7a929af6f314d0609c">강화학습을 정의하려면 행동심리학의 강화라는 개념 이외에 머신러닝을 알아야 하는데 머신러닝은 다음과 같이 크게 세 가지로 나뉜다.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-e99dfcc0aabd4ce2a1c044074277abde"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:384px;max-width:100%;flex-direction:column"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%272000%27%20height=%271437%27/%3e"/></span><img alt="머신러닝의 종류" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover;background-size:cover;background-position:0% 0%;filter:blur(20px);background-image:url(&quot;data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAAAwAgCdASoQAAsABUB8JbACdDiMwP18E8JcwAD+8eBmkpSrFZsN3Tv2PDn63bgnxdVShREgdU+8OEyvs8HnWtAFYfZ7ETZhp2ARptd18NZPUtXjo0IjowAA&quot;)"/><noscript><img alt="머신러닝의 종류" src="https://www.notion.so/image/https%3A%2F%2Flongshiine.github.io%2F2021%2F01%2F19%2FReinforcement-Learning-Intro%2Flearning.png?table=block&amp;id=e99dfcc0-aabd-4ce2-a1c0-44074277abde&amp;cache=v2" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></span><figcaption class="notion-asset-caption">머신러닝의 종류</figcaption></div></figure><div class="notion-blank notion-block-7879e962bf2044bf82da32fc07e7aaed"> </div><ul class="notion-list notion-list-disc notion-block-62070792284c49b192b2dbffeb7a19cc"><li><code class="notion-inline-code">지도학습(Supervised Learning)</code>: 회귀분석(Regression), 분류(Classification)</li></ul><ul class="notion-list notion-list-disc notion-block-57ece6a865ca466f9ab08cc985998c80"><li><code class="notion-inline-code">비지도학습(Unsupervised Learning)</code>: 군집화(Clustering)</li></ul><ul class="notion-list notion-list-disc notion-block-724621ff40834910ba88d2669cbd6b0e"><li><code class="notion-inline-code">강화학습(Reinforcement Learning)</code></li></ul><div class="notion-text notion-block-b3b4d208b4f045ad944c09b98cc44419">강화학습은 지도학습, 비지도학습과 그 성격이다르다. 정답이 주어진 것은 아니지만 그저 주어진 데이터에 대해 학습하는 것도 아니기 때문이다. 강화학습은 <b>보상(reward)</b> 을 통해 학습한다. 보상은 컴퓨터가 선택한 <b>행동(Action)</b> 에 대한 환경의 반응이다. 이 보상은 직접적인 답은 아니지만 컴퓨터에게는 간접적인 정답의 역할을 한다.</div><div class="notion-text notion-block-2c63bb92a65d47bea8ce603954232969">강화학습을 수행하는 컴퓨터는 행동심리학에서 살펴본 강화처럼 보상을 얻게 하는 행동을 점점 많이 하도록 학습한다.</div><div class="notion-blank notion-block-28800e22f10c41f381653c866ef19d8f"> </div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-0ef4304d1fe7485d9d7ce7fbfbdf8ee6" data-id="0ef4304d1fe7485d9d7ce7fbfbdf8ee6"><span><div id="0ef4304d1fe7485d9d7ce7fbfbdf8ee6" class="notion-header-anchor"></div><a class="notion-hash-link" href="#0ef4304d1fe7485d9d7ce7fbfbdf8ee6" title="스스로 학습하는 컴퓨터, 에이전트"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>스스로 학습하는 컴퓨터, 에이전트</b></span></span></h4><div class="notion-text notion-block-e3574bf7454b428e9bc57815e97497aa">앞으로 강화학습을 통해 스스로 학습하는 컴퓨터를 <code class="notion-inline-code">에이전트(Agent)</code>라고 할 것이다. 에이전트는 환경에 대해 사전지식이 없는 상태에서 학습을 한다. 에이전트는 자신이 놓인 환경에서 자신의 상태를 인식한 후 행동한다. 그러면 환경은 에이전트에게 보상을 주고 다음 상태를 알려준다(아래의 그림처럼 말이다!). 에이전트는 자신의 행동과 행동의 결과를 보상을 통해 학습하면서 어떤 행동을 해야 좋은 결과를 얻게 되는지 알게 된다.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-b42d5c674f684074a4db57103dc602c2"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:576px;max-width:100%;flex-direction:column"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%272000%27%20height=%27796%27/%3e"/></span><img alt="Agent" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover;background-size:cover;background-position:0% 0%;filter:blur(20px);background-image:url(&quot;data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAADwAQCdASoQAAYABUB8JbAAAxU/hK+OgYAA/usWk5kxNkQhp8kUZ3p6QSN3VyFtHXc4Z/ij8047CJaVylfx4Z1HWszAAA==&quot;)"/><noscript><img alt="Agent" src="https://www.notion.so/image/https%3A%2F%2Flongshiine.github.io%2F2021%2F01%2F19%2FReinforcement-Learning-Intro%2Fagent.png?table=block&amp;id=b42d5c67-4f68-4074-a4db-57103dc602c2&amp;cache=v2" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></span><figcaption class="notion-asset-caption">Agent</figcaption></div></figure><div class="notion-blank notion-block-d3e644f783b84ea99250ab6268b30103"> </div><div class="notion-text notion-block-cebc960ff2124af68a35c8a8e80ae605">강화학습의 목적은 에이전트가 환경을 탐색하면서 얻는 보상들의 합을 최대화하는 <code class="notion-inline-code">최적의 행동양식, 또는 정책</code>을 학습하는 것이다.</div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-716d3dd917f3488fa23c3a5a3974d201" data-id="716d3dd917f3488fa23c3a5a3974d201"><span><div id="716d3dd917f3488fa23c3a5a3974d201" class="notion-header-anchor"></div><a class="notion-hash-link" href="#716d3dd917f3488fa23c3a5a3974d201" title="강화학습의 장점"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>강화학습의 장점</b></span></span></h4><div class="notion-text notion-block-d6822efeae2e4fef80c1323d91591cd5">이러한 강화학습의 장점은 무엇일까?</div><blockquote class="notion-quote notion-block-f9bde94373554533b97866928e586b64"><div>“환경에 대한 사전지식이 없어도 학습한다는 것”</div></blockquote><div class="notion-text notion-block-10e42557ba3f4fbd985d1fb773626fd7">실제 세상에서 에이전트가 어떠한 기능을 학습하려면 다양한 상황에 대한 정보가 있어야 한다. 이러한 정보 없이 에이전트는 시행착오를 통해 어떠한 기능을 학습한다. 알파고에 대해 강화학습 관점에서 생각해보면, 알파고 또한 바둑이라는 게임의 규칙과 사전지식이 없는 상태에서 바둑을 두면서 학습한 것이다. 처음에는 무작위로 바둑돌을 놓다가 어쩌다가 상대방을 이기기 된다. 그러면 에이전트는 보상을 받고 상대방을 이기게 한 행동을 더 하려고 한다(실제로 알파고는 바둑을 학습할 때 사람이 둔 기보를 통해 지도학습을 하는 단계도 있지만 이 책에서는 해당 내용을 생략한다)</div><div class="notion-blank notion-block-c0c51f87adcb4afd8bf90048e88c3435"> </div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-c314367d452840f3bb6096791b61b275" data-id="c314367d452840f3bb6096791b61b275"><span><div id="c314367d452840f3bb6096791b61b275" class="notion-header-anchor"></div><a class="notion-hash-link" href="#c314367d452840f3bb6096791b61b275" title="순차적 행동 결정 문제"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>순차적 행동 결정 문제</b></span></span></h4><div class="notion-text notion-block-2beb32e092a3486d9f0a9c1def2b4f68">강화학습은 마치 사람처럼 환경과 상호작용하면서 스스로 학습하는 방식이다. 하지만 다른 머신러닝과 마찬가지로 강화학습은 문제 자체에 대해 잘 이해하지 않으면 엉뚱한 결과를 낳는다. 강화학습은 어떤 문제에 적용할까?</div><blockquote class="notion-quote notion-block-8a4163356e644b7b9f3a0f900f09527c"><div>“강화학습은 결정을 순차적으로 내려야 하는 문제에 적용된다”</div></blockquote><div class="notion-text notion-block-ccfbe61623364c3fb2bc33cccff45df6">결정을 순차적으로 내려야하는 문제라는 것은 예를 들어 현재 위치에서 행동을 한번 선택하는 것이 아니라 계속적으로 선택해야 하는 아래의 게임 같은 것이다.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-4ea30491a7b64b4a8b5f1e57b17b4a54"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:432px;max-width:100%;flex-direction:column"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%272000%27%20height=%271503%27/%3e"/></span><img alt="순차적으로 행동을 결정해야 하는 문제" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover;background-size:cover;background-position:0% 0%;filter:blur(20px);background-image:url(&quot;data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAAAwAgCdASoQAAwABUB8JYgC7DBAAZCFmlGoAAD+CZMoU2eJqSxc/jMOYE9WFevOV+qmaSqXmdRenAgcVTZE7yALpygAAA==&quot;)"/><noscript><img alt="순차적으로 행동을 결정해야 하는 문제" src="https://www.notion.so/image/https%3A%2F%2Flongshiine.github.io%2F2021%2F01%2F19%2FReinforcement-Learning-Intro%2Fgame.png?table=block&amp;id=4ea30491-a7b6-4b4a-8b5f-1e57b17b4a54&amp;cache=v2" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></span><figcaption class="notion-asset-caption">순차적으로 행동을 결정해야 하는 문제</figcaption></div></figure><div class="notion-text notion-block-40c2ba3fd3234cd7a6ee5a08add15f14">에이전트가 문제에 대하여 학습하고 발전하려면 <b>문제를 수학적으로 표현</b> 해야한다. 순차적으로 행동을 결정하는 문제를 정의할 때 사용하는 방법이 <code class="notion-inline-code">MDP(Markov Decision Process)</code>이다. MDP는 순차적 행동 결정문제를 수학적으로 정의해서 에이전트가 순차적 행동 결정 문제에 접근할 수 있게 한다.</div><div class="notion-blank notion-block-f178634b7e1e4555b46848eb7954a688"> </div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-a17764008d0848319b16d7f9fa37a5cf" data-id="a17764008d0848319b16d7f9fa37a5cf"><span><div id="a17764008d0848319b16d7f9fa37a5cf" class="notion-header-anchor"></div><a class="notion-hash-link" href="#a17764008d0848319b16d7f9fa37a5cf" title="순차적 행동 결정 문제의 구성요소"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>순차적 행동 결정 문제의 구성요소</b></span></span></h4><div class="notion-text notion-block-d2fb30adb8fa4b82b418bbff8f17c299">수학적으로 정의된 문제는 다음과 같은 구성요소를 가진다. 이 구성 요소들을 MDP라 부르며 2장에서 자세히 다룬다.</div><div class="notion-text notion-block-3fffe2f821b143f89fff5f988506b503"><b>상태(state)</b></div><div class="notion-text notion-block-096ba4d625fa41fd995e3e80a4104a37">에이전트의 상태를 뜻하는데 이러한 상태에는 정적인 요소 뿐만아니라 에이전트가 움직이는 속도와 같은 동적인 요소 또한 포함된다. 가령 탁구를 치는 에이전트를 가정하면 탁구공의 위치, 속도, 가속도 같은 정보가 상태로 주어져야 한다.</div><div class="notion-text notion-block-92caa1fb3fbd41c3b59d3af9161d5a6d"><b>행동(action)</b></div><div class="notion-text notion-block-010182efebae4ec9864d7fee123ee82a">에이전트가 어떠한 상태에서 취할 수 있는 행동으로서 “상”,”하”,”좌”,”우”와 같은 것을 말한다. 게임에서의 행동이라면 게임기를 통해 줄 수 있는 입력일 것이다. 학습이 되지 않은 에이전트는 어떤 행동이 좋은 행동인지에 대한 정보가 전혀 없다. 하지만 에이전트는 학습하면서 특정한 행동들을 할 확률을 높인다. 에이전트가 행동을 취하면 환경은 에이전트에게 보상을 주고 다음 상태를 알려준다.</div><div class="notion-text notion-block-3201f65d08284b5a98873504d69543d3"><b>보상(reward)</b></div><div class="notion-text notion-block-3485570e26ac400a96c010813dbf0caf">보상은 강화학습을 다른 머신러닝 기법과 다르게 만들어주는 가장 핵심적인 요소이다. 사실상 에이전트가 학습할 수 있는 유일한 정보가 바로 보상이다. 앞서 언급했듯 강화학습의 목표는 시간에 따라 얻는 보상들의 합을 최대로 하는 정책을 찾는 것이다. 보상은 에이전트에 속하지 않는 환경의 일부이며, 에이전트는 어떤 상황에서 얼마의 보상이 나오는지에 대해 미리 알지 못한다.</div><div class="notion-text notion-block-a0cba4b50be4478680e697d2b8a5ed04"><b>정책(policy)</b></div><div class="notion-text notion-block-03e41ff7f1054fb1a28a6c24a0fef504">순차적 행동 결정 문제에서 구해야할 답은 바로 <code class="notion-inline-code">정책</code>이다. 에이전트가 보상을 얻으려면 행동을 해야 하는데 특정 상태가 아닌 모든 상태에 대해 어떤 행동을 해야 할지 알아야 한다. 이렇게 모든 상태에 대해 에이전트가 어떤 행동을 해야하는지 정해놓은 것이 정책이다.</div><div class="notion-text notion-block-a218d606e9774511a495ae93c70e8ae4">순차적 행동 결정 문제를 풀었다고 한다면 제일 좋은 정책을 에이전트가 얻었다는 것이다. 제일 좋은 정책은 <code class="notion-inline-code">최적정책(optimal policy)</code>이라고 하며 에이전트는 최적 정책에 따라 행동했을 때 보상의 합을 최대로 받을 수 있다.</div><div class="notion-blank notion-block-f6b9ea38e7684277bc839616759bf997"> </div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-35b6ae3b16874901aa3473c1ff1a731a" data-id="35b6ae3b16874901aa3473c1ff1a731a"><span><div id="35b6ae3b16874901aa3473c1ff1a731a" class="notion-header-anchor"></div><a class="notion-hash-link" href="#35b6ae3b16874901aa3473c1ff1a731a" title="강화학습의 예시: 브레이크 아웃"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>강화학습의 예시: 브레이크 아웃</b></span></span></h4><div class="notion-text notion-block-ff644089759741669aec80b03bdce0f4">이 책에서는 강화학습을 통해 몇가지 간단한 게임을 학습해본다. 그중에서 마지막 게임인 “브레이크 아웃” 즉, 벽돌깨기에 강화학습을 어떤 식으로 적용하는지 알아보자.</div><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-bf01bc8899c246798491a193b18b2323"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:288px;max-width:100%;flex-direction:column"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%272000%27%20height=%272625%27/%3e"/></span><img alt="break out" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover;background-size:cover;background-position:0% 0%;filter:blur(20px);background-image:url(&quot;data:image/webp;base64,UklGRlYAAABXRUJQVlA4IEoAAAAQAgCdASoMABAABUB8JaACdEf/gegjQMzMAP7Zq+ufJmGVaXN5ZFKy+H1STmwtChsvxB74q6JtZA+fDMK7KJYaOT/c+JYjDzsAAA==&quot;)"/><noscript><img alt="break out" src="https://www.notion.so/image/https%3A%2F%2Flongshiine.github.io%2F2021%2F01%2F19%2FReinforcement-Learning-Intro%2Fbreakout.jpg?table=block&amp;id=bf01bc88-99c2-4679-8491-a193b18b2323&amp;cache=v2" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></span><figcaption class="notion-asset-caption">break out</figcaption></div></figure><div class="notion-blank notion-block-a8577b21d26d473284d3531d3b3a30e9"> </div><div class="notion-text notion-block-b71d51aaeb92427b97ef12b08c3d4a70"><b>벽돌깨기에 강화학습을 적용하려면 어떻게 해야할까?</b>이 말은 곧 <b>벽돌깨기의 MDP를 어떻게 구성해야 할까?</b> 라는 질문과도 같다. 또한 에이전트는 어떻게 학습을 해야할지에 대해서도 생각을 해보아야 한다.</div><ol start="1" class="notion-list notion-list-numbered notion-block-956416114d434935aef5aa553215dfb6"><li>MDP</li></ol><ul class="notion-list notion-list-disc notion-block-664199f281d548da8b54218774ff1c24"><li><code class="notion-inline-code">상태</code>: 게임화면, 위의 그림과 같은 4개의 화면이 상태로 에이전트에게 제공되며, 이때 화면은 흑백화면이기 때문에 2차원 픽셀 데이터이다.</li></ul><ul class="notion-list notion-list-disc notion-block-9b5885e97d874b7680379078ecf07777"><li><code class="notion-inline-code">행동</code>: 제자리, 왼쪽 오른쪽, 발사가 가능하고 발사는 시작 때에만 가능하다.</li></ul><ul class="notion-list notion-list-disc notion-block-9eaa3bd625f642acb29c45f94f7c3f80"><li><code class="notion-inline-code">보상</code>: 벽돌이 하나씩 깨질 때마다 보상을 (+1)씩 받고 더 위쪽을 깰수록 더 큰 보상을 받는다. 아무것도 깨지 않을 때는 보상으로 (0)을 바고, 공을 놓쳐 목숨을 잃는다면 (-1)을 받는다.</li></ul><ol start="1" class="notion-list notion-list-numbered notion-block-4acd020f3e784af2a52958a33a555d40"><li>학습</li></ol><ul class="notion-list notion-list-disc notion-block-a7f0d1c731bb4d218d33850609276e7e"><li>에이전트는 4개의 연속된 게임 화면을 입력으로 받는다.</li></ul><ul class="notion-list notion-list-disc notion-block-bef5f57ab6cb46338097abff9fe0ea82"><li>처음에는 아무것도 모르므로 임의로 행동을 취한다.</li></ul><ul class="notion-list notion-list-disc notion-block-59b8a5e049a340bf9eb2c19d16c3ad50"><li>그에 따라 보상을 받게 되면 그 보상을 통해 학습한다.</li></ul><ul class="notion-list notion-list-disc notion-block-c8a25e8f850346e3a62ce07e05f404b5"><li>결국 사람처럼 혹은 사람보다 잘하게 된다.</li></ul><figure class="notion-asset-wrapper notion-asset-wrapper-image notion-block-15621a9e5ba64310b387b5053c23cb44"><div style="position:relative;display:flex;justify-content:center;align-self:center;width:528px;max-width:100%;flex-direction:column"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%272000%27%20height=%27890%27/%3e"/></span><img alt="DQN" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover;background-size:cover;background-position:0% 0%;filter:blur(20px);background-image:url(&quot;data:image/webp;base64,UklGRkgAAABXRUJQVlA4IDwAAACwAQCdASoQAAcABUB8JaQAApQdbsHwAPlz5EUPq+WIXENeBw/kh9Xa7C7cYO0DxtpfLpbw8y5UrysAAAA=&quot;)"/><noscript><img alt="DQN" src="https://www.notion.so/image/https%3A%2F%2Flongshiine.github.io%2F2021%2F01%2F19%2FReinforcement-Learning-Intro%2FDQN.png?table=block&amp;id=15621a9e-5ba6-4310-b387-b5053c23cb44&amp;cache=v2" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover" loading="lazy"/></noscript></span><figcaption class="notion-asset-caption">DQN</figcaption></div></figure><div class="notion-text notion-block-afc46bf6ea5446c6b866e0cc0dfe699d">강화학습을 통해 학습되는 것은 <b>인공신경망이다</b>(인공신경망에 대해서는 5장에서 다뤄진다.) 인공신경망의 입력으로 위의 그림과 같은 4개의 연속적인 게임 화면이 들어온다. 인공신경망으로 입력이 들어오면 그 상태에서 에이전트가 할 수 있는 행동이 얼마나 좋은지 출력으로 내놓는다. 행동이 얼마나 좋은지가 행동의 가치가 되고 이것을 <code class="notion-inline-code">큐함수(Q Function)</code>라고 한다.</div><div class="notion-text notion-block-4fff7ca4d9494212a5ae132a301b63d7">이 문제에 사용한 인공신경망을 <code class="notion-inline-code">DQN(Deep Q-Network)</code>라고 하는데 DQN에 상태가 입력으로 들어오면 DQN은 그 상태에서 제자리, 왼쪽, 오른쪽 행동의 큐함수를 출력으로 내놓는다. 에이전트는 출력으로 나오는 큐함수에 따라서 행동한다. 즉, DQN이 출력한 큐함수를 보고 큰가치를 지니는 행동을 선택하는 것이다. 에이전트가 그행동을 취하면 환경은 에이전트에게 보상과 다음 상태를 알려준다. 에이전트는 환경과 상호작용하면서 DQN을 더 많은 보상을 받도록 조금씩 조정한다.</div><div class="notion-text notion-block-d91ac7a5ee4643f789a7fad012712a24">에이전트는 이와 같은 방식으로 벽돌깨기를 학습하는데, 이 예제에 대한 자세한 이론과 코드는 뒤에서 다루어진다. 여기서는 어떤 흐름으로 에이전트가 강화학습을 통해 학습하는 지를 아는 것이 목적이다.</div><div class="notion-blank notion-block-d8f48f233cc84e3695012ced502a8843"> </div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-55841c0262f24a0584d88b5180a3908b" data-id="55841c0262f24a0584d88b5180a3908b"><span><div id="55841c0262f24a0584d88b5180a3908b" class="notion-header-anchor"></div><a class="notion-hash-link" href="#55841c0262f24a0584d88b5180a3908b" title="사람과 강화학습 에이전트의 차이"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>사람과 강화학습 에이전트의 차이</b></span></span></h4><div class="notion-text notion-block-bd69376c3dd44956b29eee6d1ae23c78">에이전트가 강화학습을 통해 벽돌깨기를 학습하는 것은 사람의 학습 과정과 비슷한 면이 있다. 비슷한 점은 사람이 게임 화면을 보고 학습해 나가듯이 에이전트 또한 화면을 보고 학습한다는 점이다.</div><div class="notion-text notion-block-56981941a8e24fc3b7e52a9cfff5448b">하지만 사람과 다른 점 또한 있다. 그것은 에이전트는 게임의 규칙을 전혀 모른다는 것이다. 아마도 처음 벽돌깨기를 하는 사람이 있다면 게임을 시작하기 이전에 먼저 규칙이 무엇인지를 찾아본 뒤, 의도를 가지고 점수를 올려나갈 것이다. 어떻게 보면 게임의 규칙을 몰라도 학습할 수 있다는 것은 강화학습의 장점이면서도 초반의 느린 학습의 원인이기도 하다.</div><div class="notion-text notion-block-879b7baaef164d23bd739fe2281fb144">잘하는 친구가 옆에서 가르쳐준다면 더 빠르게 배울 수 있지 않을까? 사람은 하나를 학습하면 다른곳에도 그 학습이 영향을 미친다. 예를 들어, 어떤학생이 수학을 배웠다면 과학을 배우기에도 더 수월한 것 처럼. 하지만 현재 강화학습 에이전트는 각 학습을 다 별개로 취급해서 항상 바닥부터 학습해야 한다.</div><div class="notion-text notion-block-a5f9f23cb9894bd69005c858b0fadff0">이렇게 간단히 살펴본 사람과 강화학습 에이전트의 차이는 현재 및 미래 강화학습 분야의 연구 분야로서 지속적으로 해결해야 할 과제이다.</div><div class="notion-blank notion-block-0db79947bec94ae4bf6a58762eb4dc3f"> </div><h4 class="notion-h notion-h3 notion-h-indent-1 notion-block-8768c63f941e4a109119522fc131793f" data-id="8768c63f941e4a109119522fc131793f"><span><div id="8768c63f941e4a109119522fc131793f" class="notion-header-anchor"></div><a class="notion-hash-link" href="#8768c63f941e4a109119522fc131793f" title="1장 한줄평"><svg viewBox="0 0 16 16" width="16" height="16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><span class="notion-h-title"><b>1장 한줄평</b></span></span></h4><blockquote class="notion-quote notion-block-809975386c5f4f72bcbeba70dec62d58"><div>블로그 포스팅 너무 빡세다.. 연습 필요..</div></blockquote><div class="notion-blank notion-block-3f42188dae464f78ae58c62b866cb4a2"> </div></article><aside class="notion-aside"></aside></div></main></div></div></div><div style="width:100%;background-color:#ffffff;color:#373534;padding:20px"><div id="disqus_recommendations"></div><div id="disqus_thread"></div><footer class="styles_footer__RBpyk"><div class="styles_copyright__nhL_k">Copyright 2023 <!-- -->Jang Yeong</div><div class="styles_settings__GyEhi"></div><div class="styles_social__ptL3p"><a class="styles_github__0JN7a" href="https://github.com/longshiine" title="GitHub @longshiine" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 496 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></a><a class="styles_linkedin__bgwDi" href="https://www.linkedin.com/in/jangyeong-kim-b7924422a" title="LinkedIn Jang Yeong" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"></path></svg></a><a class="styles_instagram__BY5Hj" href="https://instagram.com/jang.inspiration" title="Instagram Jang Yeong" target="_blank" rel="noopener noreferrer"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><g><path fill="none" d="M0 0h24v24H0z"></path><path fill-rule="nonzero" d="M12 2c2.717 0 3.056.01 4.122.06 1.065.05 1.79.217 2.428.465.66.254 1.216.598 1.772 1.153a4.908 4.908 0 0 1 1.153 1.772c.247.637.415 1.363.465 2.428.047 1.066.06 1.405.06 4.122 0 2.717-.01 3.056-.06 4.122-.05 1.065-.218 1.79-.465 2.428a4.883 4.883 0 0 1-1.153 1.772 4.915 4.915 0 0 1-1.772 1.153c-.637.247-1.363.415-2.428.465-1.066.047-1.405.06-4.122.06-2.717 0-3.056-.01-4.122-.06-1.065-.05-1.79-.218-2.428-.465a4.89 4.89 0 0 1-1.772-1.153 4.904 4.904 0 0 1-1.153-1.772c-.248-.637-.415-1.363-.465-2.428C2.013 15.056 2 14.717 2 12c0-2.717.01-3.056.06-4.122.05-1.066.217-1.79.465-2.428a4.88 4.88 0 0 1 1.153-1.772A4.897 4.897 0 0 1 5.45 2.525c.638-.248 1.362-.415 2.428-.465C8.944 2.013 9.283 2 12 2zm0 5a5 5 0 1 0 0 10 5 5 0 0 0 0-10zm6.5-.25a1.25 1.25 0 0 0-2.5 0 1.25 1.25 0 0 0 2.5 0zM12 9a3 3 0 1 1 0 6 3 3 0 0 1 0-6z"></path></g></svg></a></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"site":{"domain":"jang-inspiration.com","name":"Jang. Inspiration","rootNotionPageId":"6246082f40144d0698ab59e9840b298a","rootNotionSpaceId":null,"description":"장영의 영감노트"},"recordMap":{"block":{"3fd51011-fdfe-4366-931c-6ed584049b34":{"role":"reader","value":{"id":"3fd51011-fdfe-4366-931c-6ed584049b34","version":1638,"type":"page","properties":{"==~K":[["Yes"]],"=bhc":[["No"]],"AfoN":[["강화학습"]],"BN]P":[["Reinforcement Learning,Introduction"]],"NVm^":[["reinforcement-learning-introduction"]],"a\u003cql":[["‣",[["d",{"type":"date","start_date":"2021-01-19"}]]]],"}nqi":[["Jay"]],"~]S\u003c":[["강화학습이란 무엇인지, 탄생한 배경부터 주로 사용하는 용어까지 살펴보자. 강화학습이 풀고자하는 문제는 무엇이며, 순차적 행동 결정 문제란 무엇인지 톺아보자."]],"title":[["\u003c파이썬과 케라스로 배우는 강화학습\u003e - (1) "],["강화학습 개요",[["b"]]]]},"content":["c38ef645-2054-4c65-bbf8-c44fe333fea4","8e4b1731-b706-4f8b-ad02-3fb390a06614","5ea8d1d8-9ad0-4966-9485-d027809e2efa","5285cf35-7f42-4edd-b036-b43f5a084dcc","1ff4f586-5160-4be7-9b0d-40963e8d99d9","f2e00b57-e8f7-439e-866a-9d718b3b0973","f1aa7fb8-9aa1-4076-96f1-3d5784e013f4","07c30a74-c81d-45a5-a811-b975d2a4d043","e2dbaad8-773e-472f-982e-fdb2ea88a287","aaa9d862-1d8a-46fe-af68-2fac888e90ca","e4772403-51d9-4b6d-84d8-58ec6c6bdc3b","0b2c49b9-c79b-4019-a964-670e7c5cb1c4","1eb9408a-429a-4845-8f25-b59f09674b75","211fc506-4eba-4605-89ba-60b93077d8e2","e2f9aaa5-3780-4bbd-a10b-2a4739f20bd5","dda1262b-9e9b-4bd5-b3d3-0813ba26b7ea","64f65887-85cd-4e0f-92a5-3d3467513b77","3e22cf76-d065-4342-83e5-96ae6ded9298","d2a28517-b0a1-49cf-b8a5-a95c1e125e4c","2bc1e9a5-6fef-4a84-8b73-98336b5201d8","c79e22c3-e92a-4d73-9705-a2cb33703864","cc70ccd5-fcc3-4e8d-b37a-b7e9a5cee9af","cd6126d3-fdce-428e-8af9-6bdb118e741d","fe3b4aa7-262d-4bef-9e78-f045c2b7730c","8373d220-7c5e-4071-8d00-456778d37354","4425c807-3025-4e70-929b-5789f84e2dee","d32ec999-9473-4d7a-929a-f6f314d0609c","e99dfcc0-aabd-4ce2-a1c0-44074277abde","7879e962-bf20-44bf-82da-32fc07e7aaed","62070792-284c-49b1-92b2-dbffeb7a19cc","57ece6a8-65ca-466f-9ab0-8cc985998c80","724621ff-4083-4910-ba88-d2669cbd6b0e","b3b4d208-b4f0-45ad-944c-09b98cc44419","2c63bb92-a65d-47be-a8ce-603954232969","28800e22-f10c-41f3-8165-3c866ef19d8f","0ef4304d-1fe7-485d-9d7c-e7fbfbdf8ee6","e3574bf7-454b-428e-9bc5-7815e97497aa","b42d5c67-4f68-4074-a4db-57103dc602c2","d3e644f7-83b8-4ea9-9250-ab6268b30103","cebc960f-f212-4af6-8a35-c8a8e80ae605","716d3dd9-17f3-488f-a23c-3a5a3974d201","d6822efe-ae2e-4fef-80c1-323d91591cd5","f9bde943-7355-4533-b978-66928e586b64","10e42557-ba3f-4fbd-985d-1fb773626fd7","c0c51f87-adcb-4afd-8bf9-0048e88c3435","c314367d-4528-40f3-bb60-96791b61b275","2beb32e0-92a3-486d-9f0a-9c1def2b4f68","8a416335-6e64-4b7b-9f3a-0f900f09527c","ccfbe616-2336-4c3f-b2bc-33cccff45df6","4ea30491-a7b6-4b4a-8b5f-1e57b17b4a54","40c2ba3f-d323-4cd7-a6ee-5a08add15f14","f178634b-7e1e-4555-b468-48eb7954a688","a1776400-8d08-4831-9b16-d7f9fa37a5cf","d2fb30ad-b8fa-4b82-b418-bbff8f17c299","3fffe2f8-21b1-43f8-9fff-5f988506b503","096ba4d6-25fa-41fd-995e-3e80a4104a37","92caa1fb-3fbd-41c3-b59d-3af9161d5a6d","010182ef-ebae-4ec9-864d-7fee123ee82a","3201f65d-0828-4b5a-9887-3504d69543d3","3485570e-26ac-400a-96c0-10813dbf0caf","a0cba4b5-0be4-4786-80e6-97d2b8a5ed04","03e41ff7-f105-4fb1-a28a-6c24a0fef504","a218d606-e977-4511-a495-ae93c70e8ae4","f6b9ea38-e768-4277-bc83-9616759bf997","35b6ae3b-1687-4901-aa34-73c1ff1a731a","ff644089-7597-4166-9aec-80b03bdce0f4","bf01bc88-99c2-4679-8491-a193b18b2323","a8577b21-d26d-4732-84d3-531d3b3a30e9","b71d51aa-eb92-427b-97ef-12b08c3d4a70","95641611-4d43-4935-aef5-aa553215dfb6","664199f2-81d5-48da-8b54-218774ff1c24","9b5885e9-7d87-4b76-8037-9078ecf07777","9eaa3bd6-25f6-42ac-b29c-45f94f7c3f80","4acd020f-3e78-4af2-a529-58a33a555d40","a7f0d1c7-31bb-4d21-8d33-850609276e7e","bef5f57a-b6cb-4633-8097-abff9fe0ea82","59b8a5e0-49a3-40bf-9eb2-c19d16c3ad50","c8a25e8f-8503-46e3-a62c-e07e05f404b5","15621a9e-5ba6-4310-b387-b5053c23cb44","afc46bf6-ea54-46c6-b866-e0cc0dfe699d","4fff7ca4-d949-4212-a5ae-132a301b63d7","d91ac7a5-ee46-43f7-89a7-fad012712a24","d8f48f23-3cc8-4e36-9501-2ced502a8843","55841c02-62f2-4a05-84d8-8b5180a3908b","bd69376c-3dd4-4956-b29e-ee6d1ae23c78","56981941-a8e2-4fc3-b7e5-2a9cfff5448b","879b7baa-ef16-4d23-bd73-9fe2281fb144","a5f9f23c-b989-4bd6-9005-c858b0fadff0","0db79947-bec9-4ae4-bf6a-58762eb4dc3f","8768c63f-941e-4a10-9119-522fc131793f","80997538-6c5f-4f72-bcbe-ba70dec62d58","3f42188d-ae46-4f78-ae58-c62b866cb4a2"],"format":{"page_icon":"🎮","page_cover":"https://images.unsplash.com/photo-1563209259-b2fa97148ce1?ixlib=rb-4.0.3\u0026q=80\u0026fm=jpg\u0026crop=entropy\u0026cs=tinysrgb","block_locked":false,"block_locked_by":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","copied_from_pointer":{"id":"cacb6437-50cd-4a3d-9d43-58962f75e40b","table":"block","spaceId":"4af10338-3e65-4b50-af9f-798d59d5c8f6"},"page_cover_position":0.5},"created_time":1676022857243,"last_edited_time":1677651609594,"parent_id":"ba8460cf-4781-486e-8976-01358ef4659d","parent_table":"collection","alive":true,"copied_from":"cacb6437-50cd-4a3d-9d43-58962f75e40b","created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"4f20ede8-ccf7-4ae1-82e5-819e100dd032":{"role":"reader","value":{"id":"4f20ede8-ccf7-4ae1-82e5-819e100dd032","version":129,"type":"collection_view","view_ids":["d91647c5-6a81-48b1-a1ff-a04529d0ddba","27bc73a3-5779-44e0-b617-2f0d26f5aa2f"],"collection_id":"ba8460cf-4781-486e-8976-01358ef4659d","format":{"collection_pointer":{"id":"ba8460cf-4781-486e-8976-01358ef4659d","table":"collection","spaceId":"4af10338-3e65-4b50-af9f-798d59d5c8f6"},"copied_from_pointer":{"id":"3e3073e9-7aee-481c-b831-765e112ec7b5","table":"block","spaceId":"fde5ac74-eea3-4527-8f00-4482710e1af3"}},"created_time":1675998770865,"last_edited_time":1677136438825,"parent_id":"6246082f-4014-4d06-98ab-59e9840b298a","parent_table":"block","alive":true,"copied_from":"3e3073e9-7aee-481c-b831-765e112ec7b5","created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"6246082f-4014-4d06-98ab-59e9840b298a":{"role":"reader","value":{"id":"6246082f-4014-4d06-98ab-59e9840b298a","version":609,"type":"page","properties":{"title":[["Jang. Inspiration"]]},"content":["651dcdf3-689d-42d2-8497-64f8509d3504","0bd6df0e-6679-499e-b382-c9dc2c597776","f4c89bb7-a90e-41d7-a678-588b3deff765","d5557a1e-de5e-4085-896d-362a19928b69","4f20ede8-ccf7-4ae1-82e5-819e100dd032","ce518f27-4e46-4e98-ac75-13c467c1370c","dfee9c57-3be6-41db-8113-a54eeef675a7","1109cf3f-d8f9-4532-a13e-1af177ad4fdd","5855fe5e-17e2-4f14-8b66-702838bcc734"],"format":{"page_icon":"https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b29e9b03-c79c-4e52-a45e-7228163ba524/compass-circular-tool_(3).png","page_cover":"/images/page-cover/nasa_reduced_gravity_walking_simulator.jpg","copied_from_pointer":{"id":"78754261-97cf-4616-9880-9def95960ebf","table":"block","spaceId":"fde5ac74-eea3-4527-8f00-4482710e1af3"},"page_cover_position":0.5},"permissions":[{"role":"editor","type":"user_permission","user_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb"},{"role":"reader","type":"public_permission","added_timestamp":1675998834095}],"created_time":1675998770872,"last_edited_time":1677392850666,"parent_id":"3a2d56c9-1da9-4a62-b698-f0ad3576c8c1","parent_table":"block","alive":true,"copied_from":"78754261-97cf-4616-9880-9def95960ebf","file_ids":["f70d3dc6-ce97-4be2-9cde-b86606147b41","a2bd3317-78e4-48bc-8d27-9b733175a416","7fae9664-8795-4723-844e-0adecdea62dc","4235c094-2110-4aa6-b058-6b5fe220dbb7","c8194a03-81d0-482d-a7de-f491a6e85f54","7eb95609-c81b-48c1-969e-5ef2f220bc5a","160057d8-120e-4f9f-8c1f-6bcf31a50f15","0cb9278b-708b-4da1-929a-6696aa8cdfa3","3eb9471e-9b71-4bd3-a13d-c33158a442be","b29e9b03-c79c-4e52-a45e-7228163ba524"],"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"c38ef645-2054-4c65-bbf8-c44fe333fea4":{"role":"reader","value":{"id":"c38ef645-2054-4c65-bbf8-c44fe333fea4","version":18,"type":"quote","properties":{"title":[["본 포스트는 “파이썬과 케라스로 배우는 강화학습” 도서의 첫번째 리뷰 포스트입니다."]]},"created_time":1676022892150,"last_edited_time":1676055463168,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"8e4b1731-b706-4f8b-ad02-3fb390a06614":{"role":"reader","value":{"id":"8e4b1731-b706-4f8b-ad02-3fb390a06614","version":7,"type":"text","properties":{"title":[["http://www.yes24.com/Product/Goods/44136413",[["a","http://www.yes24.com/Product/Goods/44136413"]]]]},"created_time":1676055463163,"last_edited_time":1676055471379,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"5ea8d1d8-9ad0-4966-9485-d027809e2efa":{"role":"reader","value":{"id":"5ea8d1d8-9ad0-4966-9485-d027809e2efa","version":7,"type":"text","created_time":1676022894983,"last_edited_time":1676049184827,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"5285cf35-7f42-4edd-b036-b43f5a084dcc":{"role":"reader","value":{"id":"5285cf35-7f42-4edd-b036-b43f5a084dcc","version":4,"type":"table_of_contents","format":{"block_color":"gray"},"created_time":1676049198741,"last_edited_time":1676049198743,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"1ff4f586-5160-4be7-9b0d-40963e8d99d9":{"role":"reader","value":{"id":"1ff4f586-5160-4be7-9b0d-40963e8d99d9","version":4,"type":"text","created_time":1676022894983,"last_edited_time":1676049184945,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"f2e00b57-e8f7-439e-866a-9d718b3b0973":{"role":"reader","value":{"id":"f2e00b57-e8f7-439e-866a-9d718b3b0973","version":4,"type":"text","properties":{"title":[["방학이 어느새 1달여가 다 되어가는 시점이다..",[["b"]]],[" 😥"]]},"created_time":1676022892150,"last_edited_time":1676022897606,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"f1aa7fb8-9aa1-4076-96f1-3d5784e013f4":{"role":"reader","value":{"id":"f1aa7fb8-9aa1-4076-96f1-3d5784e013f4","version":2,"type":"text","properties":{"title":[["1달간의 잉여생활을 청산하기 위해, 서점에 들러 강화학습 도서를 집었다. 원래는 CS234를 도전해보려 했으나, 미약한 영어실력 및 충전된 잉여력으로 인해 1강을 채 못 끝내었다는 불편한 진실..을 뒤로 하고, 코드와 함께 있는 이 도서를 정독해보기로 마음먹었다. 아무래도 나는 코드가 없으면 재미를 못느끼는 타입인가 보다. 암튼암튼. 이 책 만큼은 끝까지 도달하기를 진심진심으로 바란다. (교보문고에서 무려 2만 8천원을 고대로 내고 사왔다!)"]]},"created_time":1676022892150,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"07c30a74-c81d-45a5-a811-b975d2a4d043":{"role":"reader","value":{"id":"07c30a74-c81d-45a5-a811-b975d2a4d043","version":5,"type":"text","created_time":1676022899116,"last_edited_time":1676022899119,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"e2dbaad8-773e-472f-982e-fdb2ea88a287":{"role":"reader","value":{"id":"e2dbaad8-773e-472f-982e-fdb2ea88a287","version":2,"type":"sub_header","properties":{"title":[["1장. 강화학습 개요",[["b"]]]]},"created_time":1676022892150,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"aaa9d862-1d8a-46fe-af68-2fac888e90ca":{"role":"reader","value":{"id":"aaa9d862-1d8a-46fe-af68-2fac888e90ca","version":2,"type":"divider","created_time":1676022892151,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"e4772403-51d9-4b6d-84d8-58ec6c6bdc3b":{"role":"reader","value":{"id":"e4772403-51d9-4b6d-84d8-58ec6c6bdc3b","version":2,"type":"text","properties":{"title":[["이 책의 목표는 다음과 같다."]]},"created_time":1676022892151,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"0b2c49b9-c79b-4019-a964-670e7c5cb1c4":{"role":"reader","value":{"id":"0b2c49b9-c79b-4019-a964-670e7c5cb1c4","version":2,"type":"bulleted_list","properties":{"title":[["최소한의 수식과 직관적인 그림을 통해 강화학습을 이해하는 것"]]},"created_time":1676022892151,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"1eb9408a-429a-4845-8f25-b59f09674b75":{"role":"reader","value":{"id":"1eb9408a-429a-4845-8f25-b59f09674b75","version":2,"type":"bulleted_list","properties":{"title":[["간단한 게임에 강화학습 이론을 직접 구현해보는 것"]]},"created_time":1676022892151,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"211fc506-4eba-4605-89ba-60b93077d8e2":{"role":"reader","value":{"id":"211fc506-4eba-4605-89ba-60b93077d8e2","version":2,"type":"text","properties":{"title":[["행동심리학과 머신러닝에 뿌리를 둔 강화학습에 대해 공부하려면 강화학습이 풀려고 하는 문제에 대해 정의를 먼저 해야한다. 강화학습은 다른 머신러닝 분야와 다르게 "],["순차적으로 행동을 결정해야 하는 문제",[["b"]]],["를 다루며 이러한 문제를 컴퓨터가 풀기 위해서는 문제를 수학적으로 잘 정의해야 한다."]]},"created_time":1676022892151,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"e2f9aaa5-3780-4bbd-a10b-2a4739f20bd5":{"role":"reader","value":{"id":"e2f9aaa5-3780-4bbd-a10b-2a4739f20bd5","version":5,"type":"text","created_time":1676022906518,"last_edited_time":1676022906522,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"dda1262b-9e9b-4bd5-b3d3-0813ba26b7ea":{"role":"reader","value":{"id":"dda1262b-9e9b-4bd5-b3d3-0813ba26b7ea","version":2,"type":"sub_sub_header","properties":{"title":[["스키너의 강화 연구",[["b"]]]]},"created_time":1676022892151,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"64f65887-85cd-4e0f-92a5-3d3467513b77":{"role":"reader","value":{"id":"64f65887-85cd-4e0f-92a5-3d3467513b77","version":2,"type":"text","properties":{"title":[["강화(Reinforcement)는 동물이 시행착오(Trial and Error)를 통해 학습하는 방법 중 하나이고, 행동심리학의 시행착오 학습이라는 개념은 동물들이 이것저것 시도해보면서 그 결과를 통해 학습하는 것을 말한다."]]},"created_time":1676022892151,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"3e22cf76-d065-4342-83e5-96ae6ded9298":{"role":"reader","value":{"id":"3e22cf76-d065-4342-83e5-96ae6ded9298","version":2,"type":"numbered_list","properties":{"title":[["굶긴 쥐를 상자에 넣는다."]]},"created_time":1676022892151,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d2a28517-b0a1-49cf-b8a5-a95c1e125e4c":{"role":"reader","value":{"id":"d2a28517-b0a1-49cf-b8a5-a95c1e125e4c","version":2,"type":"numbered_list","properties":{"title":[["쥐는 돌아다니다가 우연히 상자 안에 있는 지렛대를 누르게 된다."]]},"created_time":1676022892152,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"2bc1e9a5-6fef-4a84-8b73-98336b5201d8":{"role":"reader","value":{"id":"2bc1e9a5-6fef-4a84-8b73-98336b5201d8","version":2,"type":"numbered_list","properties":{"title":[["지렛대를 누르자 먹이가 나온다."]]},"created_time":1676022892152,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"c79e22c3-e92a-4d73-9705-a2cb33703864":{"role":"reader","value":{"id":"c79e22c3-e92a-4d73-9705-a2cb33703864","version":2,"type":"numbered_list","properties":{"title":[["지렛대를 누르는 행동과 먹이와의 상관관계를 모르는 쥐는 다시 돌아다닌다."]]},"created_time":1676022892152,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"cc70ccd5-fcc3-4e8d-b37a-b7e9a5cee9af":{"role":"reader","value":{"id":"cc70ccd5-fcc3-4e8d-b37a-b7e9a5cee9af","version":2,"type":"numbered_list","properties":{"title":[["그러다가 우연히 쥐가 다시 지렛대를 누르면 쥐는 이제 먹이와 지렛대 사이의 관계를 알게 되고 점점 지렛대를 자주 누르게 된다."]]},"created_time":1676022892152,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"cd6126d3-fdce-428e-8af9-6bdb118e741d":{"role":"reader","value":{"id":"cd6126d3-fdce-428e-8af9-6bdb118e741d","version":2,"type":"numbered_list","properties":{"title":[["이 과정을 반복하면서 쥐는 지렛대를 누르면 먹이를 먹을 수 있다는 것을 학습한다."]]},"created_time":1676022892152,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"fe3b4aa7-262d-4bef-9e78-f045c2b7730c":{"role":"reader","value":{"id":"fe3b4aa7-262d-4bef-9e78-f045c2b7730c","version":2,"type":"text","properties":{"title":[["즉, 강화라는 것은 동물이 이전에 배우지 않았지만 직접 시도하면서 행동과 그 결과로 나타나는 좋은 보상사이의 상관관계를 학습하는 것이다"]]},"created_time":1676022892152,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"8373d220-7c5e-4071-8d00-456778d37354":{"role":"reader","value":{"id":"8373d220-7c5e-4071-8d00-456778d37354","version":5,"type":"text","created_time":1676022909303,"last_edited_time":1676022909305,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"4425c807-3025-4e70-929b-5789f84e2dee":{"role":"reader","value":{"id":"4425c807-3025-4e70-929b-5789f84e2dee","version":2,"type":"sub_sub_header","properties":{"title":[["머신러닝과 강화학습",[["b"]]]]},"created_time":1676022892152,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d32ec999-9473-4d7a-929a-f6f314d0609c":{"role":"reader","value":{"id":"d32ec999-9473-4d7a-929a-f6f314d0609c","version":2,"type":"text","properties":{"title":[["강화학습을 정의하려면 행동심리학의 강화라는 개념 이외에 머신러닝을 알아야 하는데 머신러닝은 다음과 같이 크게 세 가지로 나뉜다."]]},"created_time":1676022892152,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"e99dfcc0-aabd-4ce2-a1c0-44074277abde":{"role":"reader","value":{"id":"e99dfcc0-aabd-4ce2-a1c0-44074277abde","version":26,"type":"image","properties":{"source":[["https://longshiine.github.io/2021/01/19/Reinforcement-Learning-Intro/learning.png"]],"caption":[["머신러닝의 종류"]]},"format":{"block_width":384,"block_full_width":false,"block_page_width":false},"created_time":1676022892152,"last_edited_time":1676022954701,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"7879e962-bf20-44bf-82da-32fc07e7aaed":{"role":"reader","value":{"id":"7879e962-bf20-44bf-82da-32fc07e7aaed","version":4,"type":"text","created_time":1676022892156,"last_edited_time":1676022944061,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"62070792-284c-49b1-92b2-dbffeb7a19cc":{"role":"reader","value":{"id":"62070792-284c-49b1-92b2-dbffeb7a19cc","version":2,"type":"bulleted_list","properties":{"title":[["지도학습(Supervised Learning)",[["c"]]],[": 회귀분석(Regression), 분류(Classification)"]]},"created_time":1676022892156,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"57ece6a8-65ca-466f-9ab0-8cc985998c80":{"role":"reader","value":{"id":"57ece6a8-65ca-466f-9ab0-8cc985998c80","version":2,"type":"bulleted_list","properties":{"title":[["비지도학습(Unsupervised Learning)",[["c"]]],[": 군집화(Clustering)"]]},"created_time":1676022892156,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"724621ff-4083-4910-ba88-d2669cbd6b0e":{"role":"reader","value":{"id":"724621ff-4083-4910-ba88-d2669cbd6b0e","version":4,"type":"bulleted_list","properties":{"title":[["강화학습(Reinforcement Learning)",[["c"]]]]},"created_time":1676022892156,"last_edited_time":1676022957507,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"b3b4d208-b4f0-45ad-944c-09b98cc44419":{"role":"reader","value":{"id":"b3b4d208-b4f0-45ad-944c-09b98cc44419","version":2,"type":"text","properties":{"title":[["강화학습은 지도학습, 비지도학습과 그 성격이다르다. 정답이 주어진 것은 아니지만 그저 주어진 데이터에 대해 학습하는 것도 아니기 때문이다. 강화학습은 "],["보상(reward)",[["b"]]],[" 을 통해 학습한다. 보상은 컴퓨터가 선택한 "],["행동(Action)",[["b"]]],[" 에 대한 환경의 반응이다. 이 보상은 직접적인 답은 아니지만 컴퓨터에게는 간접적인 정답의 역할을 한다."]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"2c63bb92-a65d-47be-a8ce-603954232969":{"role":"reader","value":{"id":"2c63bb92-a65d-47be-a8ce-603954232969","version":2,"type":"text","properties":{"title":[["강화학습을 수행하는 컴퓨터는 행동심리학에서 살펴본 강화처럼 보상을 얻게 하는 행동을 점점 많이 하도록 학습한다."]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"28800e22-f10c-41f3-8165-3c866ef19d8f":{"role":"reader","value":{"id":"28800e22-f10c-41f3-8165-3c866ef19d8f","version":5,"type":"text","created_time":1676022912142,"last_edited_time":1676022912146,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"0ef4304d-1fe7-485d-9d7c-e7fbfbdf8ee6":{"role":"reader","value":{"id":"0ef4304d-1fe7-485d-9d7c-e7fbfbdf8ee6","version":2,"type":"sub_sub_header","properties":{"title":[["스스로 학습하는 컴퓨터, 에이전트",[["b"]]]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"e3574bf7-454b-428e-9bc5-7815e97497aa":{"role":"reader","value":{"id":"e3574bf7-454b-428e-9bc5-7815e97497aa","version":2,"type":"text","properties":{"title":[["앞으로 강화학습을 통해 스스로 학습하는 컴퓨터를 "],["에이전트(Agent)",[["c"]]],["라고 할 것이다. 에이전트는 환경에 대해 사전지식이 없는 상태에서 학습을 한다. 에이전트는 자신이 놓인 환경에서 자신의 상태를 인식한 후 행동한다. 그러면 환경은 에이전트에게 보상을 주고 다음 상태를 알려준다(아래의 그림처럼 말이다!). 에이전트는 자신의 행동과 행동의 결과를 보상을 통해 학습하면서 어떤 행동을 해야 좋은 결과를 얻게 되는지 알게 된다."]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"b42d5c67-4f68-4074-a4db-57103dc602c2":{"role":"reader","value":{"id":"b42d5c67-4f68-4074-a4db-57103dc602c2","version":6,"type":"image","properties":{"source":[["https://longshiine.github.io/2021/01/19/Reinforcement-Learning-Intro/agent.png"]],"caption":[["Agent"]]},"format":{"block_width":576,"block_full_width":false,"block_page_width":false},"created_time":1676022892157,"last_edited_time":1676051868971,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d3e644f7-83b8-4ea9-9250-ab6268b30103":{"role":"reader","value":{"id":"d3e644f7-83b8-4ea9-9250-ab6268b30103","version":4,"type":"text","created_time":1676022892157,"last_edited_time":1676022963452,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"cebc960f-f212-4af6-8a35-c8a8e80ae605":{"role":"reader","value":{"id":"cebc960f-f212-4af6-8a35-c8a8e80ae605","version":2,"type":"text","properties":{"title":[["강화학습의 목적은 에이전트가 환경을 탐색하면서 얻는 보상들의 합을 최대화하는 "],["최적의 행동양식, 또는 정책",[["c"]]],["을 학습하는 것이다."]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"716d3dd9-17f3-488f-a23c-3a5a3974d201":{"role":"reader","value":{"id":"716d3dd9-17f3-488f-a23c-3a5a3974d201","version":2,"type":"sub_sub_header","properties":{"title":[["강화학습의 장점",[["b"]]]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d6822efe-ae2e-4fef-80c1-323d91591cd5":{"role":"reader","value":{"id":"d6822efe-ae2e-4fef-80c1-323d91591cd5","version":2,"type":"text","properties":{"title":[["이러한 강화학습의 장점은 무엇일까?"]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"f9bde943-7355-4533-b978-66928e586b64":{"role":"reader","value":{"id":"f9bde943-7355-4533-b978-66928e586b64","version":2,"type":"quote","properties":{"title":[["“환경에 대한 사전지식이 없어도 학습한다는 것”"]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"10e42557-ba3f-4fbd-985d-1fb773626fd7":{"role":"reader","value":{"id":"10e42557-ba3f-4fbd-985d-1fb773626fd7","version":2,"type":"text","properties":{"title":[["실제 세상에서 에이전트가 어떠한 기능을 학습하려면 다양한 상황에 대한 정보가 있어야 한다. 이러한 정보 없이 에이전트는 시행착오를 통해 어떠한 기능을 학습한다. 알파고에 대해 강화학습 관점에서 생각해보면, 알파고 또한 바둑이라는 게임의 규칙과 사전지식이 없는 상태에서 바둑을 두면서 학습한 것이다. 처음에는 무작위로 바둑돌을 놓다가 어쩌다가 상대방을 이기기 된다. 그러면 에이전트는 보상을 받고 상대방을 이기게 한 행동을 더 하려고 한다(실제로 알파고는 바둑을 학습할 때 사람이 둔 기보를 통해 지도학습을 하는 단계도 있지만 이 책에서는 해당 내용을 생략한다)"]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"c0c51f87-adcb-4afd-8bf9-0048e88c3435":{"role":"reader","value":{"id":"c0c51f87-adcb-4afd-8bf9-0048e88c3435","version":5,"type":"text","created_time":1676022990930,"last_edited_time":1676022990935,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"c314367d-4528-40f3-bb60-96791b61b275":{"role":"reader","value":{"id":"c314367d-4528-40f3-bb60-96791b61b275","version":2,"type":"sub_sub_header","properties":{"title":[["순차적 행동 결정 문제",[["b"]]]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"2beb32e0-92a3-486d-9f0a-9c1def2b4f68":{"role":"reader","value":{"id":"2beb32e0-92a3-486d-9f0a-9c1def2b4f68","version":2,"type":"text","properties":{"title":[["강화학습은 마치 사람처럼 환경과 상호작용하면서 스스로 학습하는 방식이다. 하지만 다른 머신러닝과 마찬가지로 강화학습은 문제 자체에 대해 잘 이해하지 않으면 엉뚱한 결과를 낳는다. 강화학습은 어떤 문제에 적용할까?"]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"8a416335-6e64-4b7b-9f3a-0f900f09527c":{"role":"reader","value":{"id":"8a416335-6e64-4b7b-9f3a-0f900f09527c","version":2,"type":"quote","properties":{"title":[["“강화학습은 결정을 순차적으로 내려야 하는 문제에 적용된다”"]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"ccfbe616-2336-4c3f-b2bc-33cccff45df6":{"role":"reader","value":{"id":"ccfbe616-2336-4c3f-b2bc-33cccff45df6","version":2,"type":"text","properties":{"title":[["결정을 순차적으로 내려야하는 문제라는 것은 예를 들어 현재 위치에서 행동을 한번 선택하는 것이 아니라 계속적으로 선택해야 하는 아래의 게임 같은 것이다."]]},"created_time":1676022892157,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"4ea30491-a7b6-4b4a-8b5f-1e57b17b4a54":{"role":"reader","value":{"id":"4ea30491-a7b6-4b4a-8b5f-1e57b17b4a54","version":8,"type":"image","properties":{"source":[["https://longshiine.github.io/2021/01/19/Reinforcement-Learning-Intro/game.png"]],"caption":[["순차적으로 행동을 결정해야 하는 문제"]]},"format":{"block_width":432,"block_full_width":false,"block_page_width":false},"created_time":1676022892157,"last_edited_time":1676051873704,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"40c2ba3f-d323-4cd7-a6ee-5a08add15f14":{"role":"reader","value":{"id":"40c2ba3f-d323-4cd7-a6ee-5a08add15f14","version":2,"type":"text","properties":{"title":[["에이전트가 문제에 대하여 학습하고 발전하려면 "],["문제를 수학적으로 표현",[["b"]]],[" 해야한다. 순차적으로 행동을 결정하는 문제를 정의할 때 사용하는 방법이 "],["MDP(Markov Decision Process)",[["c"]]],["이다. MDP는 순차적 행동 결정문제를 수학적으로 정의해서 에이전트가 순차적 행동 결정 문제에 접근할 수 있게 한다."]]},"created_time":1676022892158,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"f178634b-7e1e-4555-b468-48eb7954a688":{"role":"reader","value":{"id":"f178634b-7e1e-4555-b468-48eb7954a688","version":5,"type":"text","created_time":1676023001708,"last_edited_time":1676023001712,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"a1776400-8d08-4831-9b16-d7f9fa37a5cf":{"role":"reader","value":{"id":"a1776400-8d08-4831-9b16-d7f9fa37a5cf","version":2,"type":"sub_sub_header","properties":{"title":[["순차적 행동 결정 문제의 구성요소",[["b"]]]]},"created_time":1676022892158,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d2fb30ad-b8fa-4b82-b418-bbff8f17c299":{"role":"reader","value":{"id":"d2fb30ad-b8fa-4b82-b418-bbff8f17c299","version":4,"type":"text","properties":{"title":[["수학적으로 정의된 문제는 다음과 같은 구성요소를 가진다. 이 구성 요소들을 MDP라 부르며 2장에서 자세히 다룬다."]]},"created_time":1676022892158,"last_edited_time":1676051884583,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"3fffe2f8-21b1-43f8-9fff-5f988506b503":{"role":"reader","value":{"id":"3fffe2f8-21b1-43f8-9fff-5f988506b503","version":4,"type":"text","properties":{"title":[["상태(state)",[["b"]]]]},"created_time":1676022892158,"last_edited_time":1676023019848,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"096ba4d6-25fa-41fd-995e-3e80a4104a37":{"role":"reader","value":{"id":"096ba4d6-25fa-41fd-995e-3e80a4104a37","version":4,"type":"text","properties":{"title":[["에이전트의 상태를 뜻하는데 이러한 상태에는 정적인 요소 뿐만아니라 에이전트가 움직이는 속도와 같은 동적인 요소 또한 포함된다. 가령 탁구를 치는 에이전트를 가정하면 탁구공의 위치, 속도, 가속도 같은 정보가 상태로 주어져야 한다."]]},"created_time":1676022892158,"last_edited_time":1676051880345,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"92caa1fb-3fbd-41c3-b59d-3af9161d5a6d":{"role":"reader","value":{"id":"92caa1fb-3fbd-41c3-b59d-3af9161d5a6d","version":4,"type":"text","properties":{"title":[["행동(action)",[["b"]]]]},"created_time":1676022892158,"last_edited_time":1676023021904,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"010182ef-ebae-4ec9-864d-7fee123ee82a":{"role":"reader","value":{"id":"010182ef-ebae-4ec9-864d-7fee123ee82a","version":4,"type":"text","properties":{"title":[["에이전트가 어떠한 상태에서 취할 수 있는 행동으로서 “상”,”하”,”좌”,”우”와 같은 것을 말한다. 게임에서의 행동이라면 게임기를 통해 줄 수 있는 입력일 것이다. 학습이 되지 않은 에이전트는 어떤 행동이 좋은 행동인지에 대한 정보가 전혀 없다. 하지만 에이전트는 학습하면서 특정한 행동들을 할 확률을 높인다. 에이전트가 행동을 취하면 환경은 에이전트에게 보상을 주고 다음 상태를 알려준다."]]},"created_time":1676022892158,"last_edited_time":1676051881466,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"3201f65d-0828-4b5a-9887-3504d69543d3":{"role":"reader","value":{"id":"3201f65d-0828-4b5a-9887-3504d69543d3","version":4,"type":"text","properties":{"title":[["보상(reward)",[["b"]]]]},"created_time":1676022892158,"last_edited_time":1676023023918,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"3485570e-26ac-400a-96c0-10813dbf0caf":{"role":"reader","value":{"id":"3485570e-26ac-400a-96c0-10813dbf0caf","version":4,"type":"text","properties":{"title":[["보상은 강화학습을 다른 머신러닝 기법과 다르게 만들어주는 가장 핵심적인 요소이다. 사실상 에이전트가 학습할 수 있는 유일한 정보가 바로 보상이다. 앞서 언급했듯 강화학습의 목표는 시간에 따라 얻는 보상들의 합을 최대로 하는 정책을 찾는 것이다. 보상은 에이전트에 속하지 않는 환경의 일부이며, 에이전트는 어떤 상황에서 얼마의 보상이 나오는지에 대해 미리 알지 못한다."]]},"created_time":1676022892158,"last_edited_time":1676051882751,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"a0cba4b5-0be4-4786-80e6-97d2b8a5ed04":{"role":"reader","value":{"id":"a0cba4b5-0be4-4786-80e6-97d2b8a5ed04","version":4,"type":"text","properties":{"title":[["정책(policy)",[["b"]]]]},"created_time":1676022892158,"last_edited_time":1676023025988,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"03e41ff7-f105-4fb1-a28a-6c24a0fef504":{"role":"reader","value":{"id":"03e41ff7-f105-4fb1-a28a-6c24a0fef504","version":2,"type":"text","properties":{"title":[["순차적 행동 결정 문제에서 구해야할 답은 바로 "],["정책",[["c"]]],["이다. 에이전트가 보상을 얻으려면 행동을 해야 하는데 특정 상태가 아닌 모든 상태에 대해 어떤 행동을 해야 할지 알아야 한다. 이렇게 모든 상태에 대해 에이전트가 어떤 행동을 해야하는지 정해놓은 것이 정책이다."]]},"created_time":1676022892158,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"a218d606-e977-4511-a495-ae93c70e8ae4":{"role":"reader","value":{"id":"a218d606-e977-4511-a495-ae93c70e8ae4","version":2,"type":"text","properties":{"title":[["순차적 행동 결정 문제를 풀었다고 한다면 제일 좋은 정책을 에이전트가 얻었다는 것이다. 제일 좋은 정책은 "],["최적정책(optimal policy)",[["c"]]],["이라고 하며 에이전트는 최적 정책에 따라 행동했을 때 보상의 합을 최대로 받을 수 있다."]]},"created_time":1676022892158,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"f6b9ea38-e768-4277-bc83-9616759bf997":{"role":"reader","value":{"id":"f6b9ea38-e768-4277-bc83-9616759bf997","version":5,"type":"text","created_time":1676023028658,"last_edited_time":1676023028665,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"35b6ae3b-1687-4901-aa34-73c1ff1a731a":{"role":"reader","value":{"id":"35b6ae3b-1687-4901-aa34-73c1ff1a731a","version":2,"type":"sub_sub_header","properties":{"title":[["강화학습의 예시: 브레이크 아웃",[["b"]]]]},"created_time":1676022892158,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"ff644089-7597-4166-9aec-80b03bdce0f4":{"role":"reader","value":{"id":"ff644089-7597-4166-9aec-80b03bdce0f4","version":2,"type":"text","properties":{"title":[["이 책에서는 강화학습을 통해 몇가지 간단한 게임을 학습해본다. 그중에서 마지막 게임인 “브레이크 아웃” 즉, 벽돌깨기에 강화학습을 어떤 식으로 적용하는지 알아보자."]]},"created_time":1676022892158,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"bf01bc88-99c2-4679-8491-a193b18b2323":{"role":"reader","value":{"id":"bf01bc88-99c2-4679-8491-a193b18b2323","version":8,"type":"image","properties":{"source":[["https://longshiine.github.io/2021/01/19/Reinforcement-Learning-Intro/breakout.jpg"]],"caption":[["break out"]]},"format":{"block_width":288,"block_full_width":false,"block_page_width":false},"created_time":1676022892158,"last_edited_time":1676051888933,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"a8577b21-d26d-4732-84d3-531d3b3a30e9":{"role":"reader","value":{"id":"a8577b21-d26d-4732-84d3-531d3b3a30e9","version":4,"type":"text","created_time":1676022892158,"last_edited_time":1676023033400,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"b71d51aa-eb92-427b-97ef-12b08c3d4a70":{"role":"reader","value":{"id":"b71d51aa-eb92-427b-97ef-12b08c3d4a70","version":2,"type":"text","properties":{"title":[["벽돌깨기에 강화학습을 적용하려면 어떻게 해야할까?",[["b"]]],["이 말은 곧 "],["벽돌깨기의 MDP를 어떻게 구성해야 할까?",[["b"]]],[" 라는 질문과도 같다. 또한 에이전트는 어떻게 학습을 해야할지에 대해서도 생각을 해보아야 한다."]]},"created_time":1676022892158,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"95641611-4d43-4935-aef5-aa553215dfb6":{"role":"reader","value":{"id":"95641611-4d43-4935-aef5-aa553215dfb6","version":2,"type":"numbered_list","properties":{"title":[["MDP"]]},"created_time":1676022892159,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"664199f2-81d5-48da-8b54-218774ff1c24":{"role":"reader","value":{"id":"664199f2-81d5-48da-8b54-218774ff1c24","version":2,"type":"bulleted_list","properties":{"title":[["상태",[["c"]]],[": 게임화면, 위의 그림과 같은 4개의 화면이 상태로 에이전트에게 제공되며, 이때 화면은 흑백화면이기 때문에 2차원 픽셀 데이터이다."]]},"created_time":1676022892159,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"9b5885e9-7d87-4b76-8037-9078ecf07777":{"role":"reader","value":{"id":"9b5885e9-7d87-4b76-8037-9078ecf07777","version":2,"type":"bulleted_list","properties":{"title":[["행동",[["c"]]],[": 제자리, 왼쪽 오른쪽, 발사가 가능하고 발사는 시작 때에만 가능하다."]]},"created_time":1676022892161,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"9eaa3bd6-25f6-42ac-b29c-45f94f7c3f80":{"role":"reader","value":{"id":"9eaa3bd6-25f6-42ac-b29c-45f94f7c3f80","version":2,"type":"bulleted_list","properties":{"title":[["보상",[["c"]]],[": 벽돌이 하나씩 깨질 때마다 보상을 (+1)씩 받고 더 위쪽을 깰수록 더 큰 보상을 받는다. 아무것도 깨지 않을 때는 보상으로 (0)을 바고, 공을 놓쳐 목숨을 잃는다면 (-1)을 받는다."]]},"created_time":1676022892161,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"4acd020f-3e78-4af2-a529-58a33a555d40":{"role":"reader","value":{"id":"4acd020f-3e78-4af2-a529-58a33a555d40","version":14,"type":"numbered_list","properties":{"title":[["학습"]]},"format":{"list_start_index":2},"created_time":1676022892161,"last_edited_time":1676023044746,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"a7f0d1c7-31bb-4d21-8d33-850609276e7e":{"role":"reader","value":{"id":"a7f0d1c7-31bb-4d21-8d33-850609276e7e","version":2,"type":"bulleted_list","properties":{"title":[["에이전트는 4개의 연속된 게임 화면을 입력으로 받는다."]]},"created_time":1676022892161,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"bef5f57a-b6cb-4633-8097-abff9fe0ea82":{"role":"reader","value":{"id":"bef5f57a-b6cb-4633-8097-abff9fe0ea82","version":2,"type":"bulleted_list","properties":{"title":[["처음에는 아무것도 모르므로 임의로 행동을 취한다."]]},"created_time":1676022892161,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"59b8a5e0-49a3-40bf-9eb2-c19d16c3ad50":{"role":"reader","value":{"id":"59b8a5e0-49a3-40bf-9eb2-c19d16c3ad50","version":2,"type":"bulleted_list","properties":{"title":[["그에 따라 보상을 받게 되면 그 보상을 통해 학습한다."]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"c8a25e8f-8503-46e3-a62c-e07e05f404b5":{"role":"reader","value":{"id":"c8a25e8f-8503-46e3-a62c-e07e05f404b5","version":2,"type":"bulleted_list","properties":{"title":[["결국 사람처럼 혹은 사람보다 잘하게 된다."]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"15621a9e-5ba6-4310-b387-b5053c23cb44":{"role":"reader","value":{"id":"15621a9e-5ba6-4310-b387-b5053c23cb44","version":10,"type":"image","properties":{"source":[["https://longshiine.github.io/2021/01/19/Reinforcement-Learning-Intro/DQN.png"]],"caption":[["DQN"]]},"format":{"block_width":528,"block_full_width":false,"block_page_width":false},"created_time":1676022892162,"last_edited_time":1676051893165,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"afc46bf6-ea54-46c6-b866-e0cc0dfe699d":{"role":"reader","value":{"id":"afc46bf6-ea54-46c6-b866-e0cc0dfe699d","version":2,"type":"text","properties":{"title":[["강화학습을 통해 학습되는 것은 "],["인공신경망이다",[["b"]]],["(인공신경망에 대해서는 5장에서 다뤄진다.) 인공신경망의 입력으로 위의 그림과 같은 4개의 연속적인 게임 화면이 들어온다. 인공신경망으로 입력이 들어오면 그 상태에서 에이전트가 할 수 있는 행동이 얼마나 좋은지 출력으로 내놓는다. 행동이 얼마나 좋은지가 행동의 가치가 되고 이것을 "],["큐함수(Q Function)",[["c"]]],["라고 한다."]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"4fff7ca4-d949-4212-a5ae-132a301b63d7":{"role":"reader","value":{"id":"4fff7ca4-d949-4212-a5ae-132a301b63d7","version":2,"type":"text","properties":{"title":[["이 문제에 사용한 인공신경망을 "],["DQN(Deep Q-Network)",[["c"]]],["라고 하는데 DQN에 상태가 입력으로 들어오면 DQN은 그 상태에서 제자리, 왼쪽, 오른쪽 행동의 큐함수를 출력으로 내놓는다. 에이전트는 출력으로 나오는 큐함수에 따라서 행동한다. 즉, DQN이 출력한 큐함수를 보고 큰가치를 지니는 행동을 선택하는 것이다. 에이전트가 그행동을 취하면 환경은 에이전트에게 보상과 다음 상태를 알려준다. 에이전트는 환경과 상호작용하면서 DQN을 더 많은 보상을 받도록 조금씩 조정한다."]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d91ac7a5-ee46-43f7-89a7-fad012712a24":{"role":"reader","value":{"id":"d91ac7a5-ee46-43f7-89a7-fad012712a24","version":2,"type":"text","properties":{"title":[["에이전트는 이와 같은 방식으로 벽돌깨기를 학습하는데, 이 예제에 대한 자세한 이론과 코드는 뒤에서 다루어진다. 여기서는 어떤 흐름으로 에이전트가 강화학습을 통해 학습하는 지를 아는 것이 목적이다."]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d8f48f23-3cc8-4e36-9501-2ced502a8843":{"role":"reader","value":{"id":"d8f48f23-3cc8-4e36-9501-2ced502a8843","version":5,"type":"text","created_time":1676023063959,"last_edited_time":1676023063963,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"55841c02-62f2-4a05-84d8-8b5180a3908b":{"role":"reader","value":{"id":"55841c02-62f2-4a05-84d8-8b5180a3908b","version":2,"type":"sub_sub_header","properties":{"title":[["사람과 강화학습 에이전트의 차이",[["b"]]]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"bd69376c-3dd4-4956-b29e-ee6d1ae23c78":{"role":"reader","value":{"id":"bd69376c-3dd4-4956-b29e-ee6d1ae23c78","version":2,"type":"text","properties":{"title":[["에이전트가 강화학습을 통해 벽돌깨기를 학습하는 것은 사람의 학습 과정과 비슷한 면이 있다. 비슷한 점은 사람이 게임 화면을 보고 학습해 나가듯이 에이전트 또한 화면을 보고 학습한다는 점이다."]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"56981941-a8e2-4fc3-b7e5-2a9cfff5448b":{"role":"reader","value":{"id":"56981941-a8e2-4fc3-b7e5-2a9cfff5448b","version":2,"type":"text","properties":{"title":[["하지만 사람과 다른 점 또한 있다. 그것은 에이전트는 게임의 규칙을 전혀 모른다는 것이다. 아마도 처음 벽돌깨기를 하는 사람이 있다면 게임을 시작하기 이전에 먼저 규칙이 무엇인지를 찾아본 뒤, 의도를 가지고 점수를 올려나갈 것이다. 어떻게 보면 게임의 규칙을 몰라도 학습할 수 있다는 것은 강화학습의 장점이면서도 초반의 느린 학습의 원인이기도 하다."]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"879b7baa-ef16-4d23-bd73-9fe2281fb144":{"role":"reader","value":{"id":"879b7baa-ef16-4d23-bd73-9fe2281fb144","version":2,"type":"text","properties":{"title":[["잘하는 친구가 옆에서 가르쳐준다면 더 빠르게 배울 수 있지 않을까? 사람은 하나를 학습하면 다른곳에도 그 학습이 영향을 미친다. 예를 들어, 어떤학생이 수학을 배웠다면 과학을 배우기에도 더 수월한 것 처럼. 하지만 현재 강화학습 에이전트는 각 학습을 다 별개로 취급해서 항상 바닥부터 학습해야 한다."]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"a5f9f23c-b989-4bd6-9005-c858b0fadff0":{"role":"reader","value":{"id":"a5f9f23c-b989-4bd6-9005-c858b0fadff0","version":2,"type":"text","properties":{"title":[["이렇게 간단히 살펴본 사람과 강화학습 에이전트의 차이는 현재 및 미래 강화학습 분야의 연구 분야로서 지속적으로 해결해야 할 과제이다."]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"0db79947-bec9-4ae4-bf6a-58762eb4dc3f":{"role":"reader","value":{"id":"0db79947-bec9-4ae4-bf6a-58762eb4dc3f","version":5,"type":"text","created_time":1676023066684,"last_edited_time":1676023066686,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"8768c63f-941e-4a10-9119-522fc131793f":{"role":"reader","value":{"id":"8768c63f-941e-4a10-9119-522fc131793f","version":2,"type":"sub_sub_header","properties":{"title":[["1장 한줄평",[["b"]]]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"80997538-6c5f-4f72-bcbe-ba70dec62d58":{"role":"reader","value":{"id":"80997538-6c5f-4f72-bcbe-ba70dec62d58","version":2,"type":"quote","properties":{"title":[["블로그 포스팅 너무 빡세다.. 연습 필요.."]]},"created_time":1676022892162,"last_edited_time":1676022892174,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"3f42188d-ae46-4f78-ae58-c62b866cb4a2":{"role":"reader","value":{"id":"3f42188d-ae46-4f78-ae58-c62b866cb4a2","version":5,"type":"text","created_time":1676023364332,"last_edited_time":1676051905328,"parent_id":"3fd51011-fdfe-4366-931c-6ed584049b34","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"3d335e41-f00a-45df-8432-34a266c7566a":{"role":"reader","value":{"id":"3d335e41-f00a-45df-8432-34a266c7566a","version":480,"type":"page","properties":{"title":[["About"]]},"content":["e1067486-5fb5-4dc3-9415-54abc63fc3a5","ab253a7b-1dec-4620-8c4e-e99f94e1f6c9","460c887f-cc3d-4351-8671-7cfbc6d3bc1d","c62b8a9d-e8cb-4c5b-be5a-48412e956c95","abe79af7-1342-438a-9a59-2d0b1ce59007","88d551b8-6b87-4540-89b9-3619a8fe4059","ae31ce74-317a-45ae-9dd3-16c14e764361","78f83c2a-05c2-4033-bcd8-945d700b2952","fd280029-9a4c-47fe-8e3c-ce8d3f146671","6a0d0c32-f1bc-4277-a128-33da8613ede4","2bcccf09-dccf-4896-8819-255cf75aabaf","d84b4bd5-3b6b-45dd-a807-5fea62c5213b","8b7fb4d3-0195-4f61-a0eb-330792f84053","e9394173-e197-4fad-a1db-ac74fdba3738","cb29948c-7258-4b05-9bfa-25bf19ad0946","a4e4243c-25aa-480d-a9ee-0af2230c7d76","172e2e25-e319-4766-ad38-02fc168994cd","6c428956-d84e-4855-a998-7a79f1fc8ea5","90f1cecf-6258-4b54-b0ee-26ee4d950872","3eec82e9-0211-4271-8c30-1dbc86ab3be1","8ce5f430-8c4c-4e8f-b6a4-23396731b27d","aeb9d85e-fffa-4c34-b253-cb0499f047a2","3d37f4c7-8064-4792-a863-234d8b4d05a6","77daa708-adbc-4092-b7f7-9e3c8a988049","26e3aca8-3e09-4a37-8c92-3c95cf579bbb"],"format":{"page_icon":"https://s3-us-west-2.amazonaws.com/secure.notion-static.com/fc853118-df50-43ed-96d9-0711493d5e25/jang_inspiration_logo.png","page_cover":"/images/page-cover/nasa_reduced_gravity_walking_simulator.jpg","copied_from_pointer":{"id":"f1199d37-579b-41cb-abfc-0b5174f4256a","table":"block","spaceId":"fde5ac74-eea3-4527-8f00-4482710e1af3"},"page_cover_position":0.5},"created_time":1675998770866,"last_edited_time":1677390731360,"parent_id":"d83b5165-627c-41b3-82f0-f1cbf904e176","parent_table":"block","alive":true,"copied_from":"f1199d37-579b-41cb-abfc-0b5174f4256a","file_ids":["c8028bee-f4c7-4736-8c36-fffcab5d977e","9407e769-d877-4de9-bbaa-9e5626d971ed","07d5a5b4-de2a-4322-bfcc-c4ade3a63b86","fc853118-df50-43ed-96d9-0711493d5e25"],"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"d83b5165-627c-41b3-82f0-f1cbf904e176":{"role":"reader","value":{"id":"d83b5165-627c-41b3-82f0-f1cbf904e176","version":17,"type":"column","content":["e1fe2c9c-6eb8-412c-9874-a8ac2fce9ed8","3d335e41-f00a-45df-8432-34a266c7566a"],"format":{"column_ratio":0.25},"created_time":1676020529237,"last_edited_time":1676091451534,"parent_id":"1109cf3f-d8f9-4532-a13e-1af177ad4fdd","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"1109cf3f-d8f9-4532-a13e-1af177ad4fdd":{"role":"reader","value":{"id":"1109cf3f-d8f9-4532-a13e-1af177ad4fdd","version":13,"type":"column_list","content":["91ac285d-9a69-4ec4-96f6-9b046a15647c","028efbb4-417e-4742-8474-dd7a2ddeb8ee","d63c036c-b99a-4aa9-a068-87abc40d37a6","d83b5165-627c-41b3-82f0-f1cbf904e176"],"format":{"block_width":720,"block_full_width":false,"block_page_width":true},"created_time":1676020365844,"last_edited_time":1676091451534,"parent_id":"6246082f-4014-4d06-98ab-59e9840b298a","parent_table":"block","alive":true,"created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"e1067486-5fb5-4dc3-9415-54abc63fc3a5":{"role":"reader","value":{"id":"e1067486-5fb5-4dc3-9415-54abc63fc3a5","version":86,"type":"text","properties":{"title":[["Instagram",[["h","blue_background"],["a","https://www.instagram.com/jang.inspiration/"]]],[" • "],["GitHub",[["h","teal_background"],["a","https://github.com/longshiine"]]],[" • "],["LinkedIn",[["h","pink_background"],["a","https://www.linkedin.com/in/jangyeong-kim-b7924422a/"]]]]},"format":{"copied_from_pointer":{"id":"0ab4ae84-463a-4b31-9430-f4ed513c5fc2","table":"block","spaceId":"fde5ac74-eea3-4527-8f00-4482710e1af3"}},"created_time":1675998770872,"last_edited_time":1676960330564,"parent_id":"3d335e41-f00a-45df-8432-34a266c7566a","parent_table":"block","alive":true,"copied_from":"0ab4ae84-463a-4b31-9430-f4ed513c5fc2","created_by_table":"notion_user","created_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","last_edited_by_table":"notion_user","last_edited_by_id":"3cb8c772-be03-4bd1-aa7d-b0df8495a3bb","space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}}},"collection":{"ba8460cf-4781-486e-8976-01358ef4659d":{"role":"reader","value":{"id":"ba8460cf-4781-486e-8976-01358ef4659d","version":117,"schema":{";KhU":{"name":"Last Updated","type":"last_edited_time"},"==~K":{"name":"Public","type":"checkbox"},"=bhc":{"name":"Curated","type":"checkbox"},"AfoN":{"name":"Category","type":"select","options":[{"id":"20579d4b-5ad0-469e-8946-2560e458bb81","color":"orange","value":"강화학습"},{"id":"b78b3694-0089-4efb-802c-c288e6190037","color":"green","value":"알고리즘"},{"id":"34c6aef1-b3b3-490e-9369-b5a385f7da4e","color":"blue","value":"딥러닝"},{"id":"67465999-8b72-4fe4-92ce-db5a812b880a","color":"brown","value":"공학수학"},{"id":"8b385c1c-8e95-4a02-b009-6215a718ebef","color":"pink","value":"글쓰기"},{"id":"435e1850-8e40-4b73-8496-0a3f694b6aeb","color":"purple","value":"스타트업"},{"id":"2b34c718-9490-4d2c-8c1d-949ea1a5010c","color":"gray","value":"독서"}]},"BN]P":{"name":"Tags","type":"multi_select","options":[{"id":"210cfb45-7eae-44e5-83dc-dba99aa3a853","color":"green","value":"Node.js"},{"id":"02b16a55-92ee-455d-9449-5e5e0a67cd04","color":"brown","value":"Computer Science"},{"id":"7993ec69-9767-4b84-adb9-5f1c907a6c77","color":"blue","value":"React.js"},{"id":"264c4a74-71d6-4015-bc91-5742970abd89","color":"yellow","value":"OSS"},{"id":"da38c5e1-f969-4abe-b28f-389b37aa22e5","color":"pink","value":"Startups"},{"id":"ceb7f269-10b7-49a9-bd4e-ba99533dee7b","color":"red","value":"Career"},{"id":"46b1d846-537f-43b5-a18c-298386278e63","color":"default","value":"Video"},{"id":"e485cc4c-e0de-4363-b442-22a0f6f588a9","color":"orange","value":"Saasify"},{"id":"5b6ee85e-ba0a-4c12-8e27-00e5b868939e","color":"gray","value":"SaaS"},{"id":"01c8627e-ae07-4f7b-b248-f877f88c8c4f","color":"purple","value":"Web Dev"},{"id":"136170f8-fe43-466b-b790-087508e8bc27","color":"blue","value":"Software Development"},{"id":"77f16ef0-4622-4f47-8f39-f5913a96421d","color":"pink","value":"Projects"},{"id":"aba9d5d2-c4f2-40ad-9f37-db6211536f92","color":"blue","value":"App Dev"},{"id":"84f76e57-8d2d-4078-bb7d-cf85520ba75c","color":"orange","value":"Lifestyle"},{"id":"38b5979d-877b-4cf4-920b-8b5da5ce9ba1","color":"yellow","value":"Thought Experiments"},{"id":"452e3943-dbcc-4d48-95fc-20d5d6339ddd","color":"orange","value":"Research"},{"id":"534e3ab2-fe89-487b-9784-71d76d5396a1","color":"purple","value":"Passion Economy"},{"id":"aa48c5a8-cfe3-4195-bfaa-25a72353299a","color":"yellow","value":"Tech"},{"id":"ff6898c4-f3f1-4024-b6a9-1cb871133744","color":"blue","value":"Creator Economy"},{"id":"ec59ba49-f2d4-4317-9a0e-3c7fb0bc60b8","color":"green","value":"Crypto"},{"id":"3fc961e4-4408-4d65-b750-7c136977ce61","color":"gray","value":"Deep Learning"},{"id":"a1419788-3341-407e-8df0-cd3d1f4ff636","color":"brown","value":"Gradient Vanishing"},{"id":"50ebe91f-e808-4056-b8ec-3b0bae45d464","color":"yellow","value":"Convolution Layer"},{"id":"ae8b3ff9-00e0-4d25-8d8d-e7389fc7fc8c","color":"orange","value":"Dot Product"},{"id":"8f6c2d82-17e0-4fb1-82eb-a6047ec75d02","color":"orange","value":"Vector"},{"id":"96ed8c32-a637-4b4f-ba99-3b397d04435a","color":"red","value":"Auction Theory"},{"id":"d4090af3-0dfb-480d-9503-0d0328774c16","color":"pink","value":"Reinforcement Learning"},{"id":"6fbb9d5c-c0f4-4791-8397-6e89c63e0c82","color":"yellow","value":"MDP"},{"id":"92885d4f-2302-43ac-87b0-e9e1c7a8cd8b","color":"yellow","value":"Introduction"},{"id":"f5ee4f74-bef9-4701-9d7d-1b9e7068d702","color":"blue","value":"Value Function"},{"id":"a575fa70-0999-44a3-b96c-262d57984b63","color":"green","value":"bellman equation"},{"id":"807f640e-1abc-476a-8300-1fe0ec0a15a3","color":"gray","value":"Grid World"},{"id":"e959edcb-aeb9-4a66-91e9-7677c68a85a8","color":"purple","value":"Dynamic Programming"},{"id":"3c5ba2f8-7ec5-4d9c-89b8-2ae975f4740a","color":"default","value":"Policy Iteration"},{"id":"b79852f3-5c3c-4de7-8d6d-731673caae40","color":"green","value":"Value Iteration"},{"id":"c2bd765b-351d-4a6d-a75d-94e8c476a180","color":"red","value":"Policy Evaluation"},{"id":"4a911c23-ca00-4f29-ad2f-463eb166f8f2","color":"brown","value":"SARSA"},{"id":"563d1a3e-095d-4ad8-bb7e-cc8c8195a9c1","color":"green","value":"Q-Learning"},{"id":"9e1bb3b2-a545-4e9d-b1eb-c47d2db8f4a8","color":"gray","value":"Writing"},{"id":"fcaf8148-917c-44bd-8ca1-fce87ba28f55","color":"blue","value":"Nepal"},{"id":"d93da022-471d-4d13-8dbc-051aa3e4639f","color":"orange","value":"Travel"},{"id":"f20c5e6f-58fe-4208-baa3-20704f665d21","color":"purple","value":"Algorithm"},{"id":"447d9963-8cfc-4c4c-9adb-88f0dc85f249","color":"red","value":"Python"},{"id":"633d7256-ffbf-4e5b-9912-906130d85250","color":"yellow","value":"Big-O"},{"id":"1a1af600-6b9b-4b8e-9483-c038712cda7c","color":"default","value":"String"},{"id":"b24d85c4-b7af-411c-905f-c9ae68eab612","color":"pink","value":"Array"},{"id":"87516a34-7662-4a77-a219-149777b960dc","color":"red","value":"LinkedList"},{"id":"d63330f6-ba17-4b9c-b370-579f4c99358a","color":"blue","value":"Stack"},{"id":"04eff27e-18a0-4883-8915-6ba26059106d","color":"yellow","value":"Queue"},{"id":"328cf039-a0b4-4b5c-90f7-be587808a1dc","color":"orange","value":"Deque"},{"id":"3364095f-3a21-47c6-8460-16ddc7f02c13","color":"brown","value":"HashTable"},{"id":"64841489-db5b-45ba-972a-7af2f53f41c7","color":"yellow","value":"Graph"},{"id":"b6dea43b-7633-4290-91f0-9761023838b0","color":"purple","value":"Tree"},{"id":"9dc575d0-d0d5-4282-8430-aae294857404","color":"gray","value":"Heap"},{"id":"edc331ab-bf6d-4985-9ecc-6884de83e8fc","color":"brown","value":"Trie"},{"id":"f2fdcca6-c69d-4b53-ab23-665ca7a223b9","color":"yellow","value":"Sort"},{"id":"5e02ca54-b743-4501-9776-62e030442114","color":"default","value":"BinarySearch"},{"id":"9a317b05-c2df-41ff-bf3f-32c39b5c451b","color":"red","value":"Greedy"},{"id":"536f3cec-7932-4444-b8c7-154672ad5fe6","color":"pink","value":"DivideAndConquer"},{"id":"1fe05376-d59a-4e4a-8596-fcd70f194621","color":"orange","value":"Basic"},{"id":"6fdde3f1-6554-4e54-ba5b-af1fc95b0ce4","color":"green","value":"Linear"},{"id":"28fc1aec-d1dd-44bb-a3ab-78ebc6f74837","color":"yellow","value":"NonLinear"},{"id":"e74e9521-68b1-4c11-ab42-a034a44dfd24","color":"blue","value":"알고리즘"},{"id":"42f167a6-7e2e-4d8e-854d-426689132f08","color":"brown","value":"Amazon"},{"id":"8aefb99d-7b6b-453b-941f-e114e32c6438","color":"blue","value":"book"},{"id":"d5083966-d1d3-4116-a615-5107104890c2","color":"pink","value":"Business"},{"id":"df607bdb-4379-4273-a45e-e52d436aef0d","color":"red","value":"Diffusion Model"},{"id":"da21253b-a1e7-4fe8-9ed3-6073a347c457","color":"orange","value":"Paper Review"}]},"NVm^":{"name":"Slug","type":"text"},"QSi`":{"name":"Series","type":"checkbox"},"a\u003cql":{"name":"Published","type":"date"},"jhf;":{"name":"Tweet","type":"text"},"nAX{":{"name":"Created","type":"created_time"},"}nqi":{"name":"Author","type":"text"},"~]S\u003c":{"name":"Description","type":"text"},"title":{"name":"Name","type":"title"}},"format":{"copied_from_pointer":{"id":"e5fdcb8e-6e29-4bc9-828d-263749307808","table":"collection","spaceId":"fde5ac74-eea3-4527-8f00-4482710e1af3"},"property_visibility":[{"property":"AfoN","visibility":"hide_if_empty"},{"property":"BN]P","visibility":"hide_if_empty"},{"property":"a\u003cql","visibility":"hide_if_empty"},{"property":"}nqi","visibility":"hide_if_empty"},{"property":"~]S\u003c","visibility":"hide"},{"property":"==~K","visibility":"hide"},{"property":"jhf;","visibility":"hide"},{"property":"=bhc","visibility":"hide"},{"property":"NVm^","visibility":"hide"},{"property":"nAX{","visibility":"hide"},{"property":";KhU","visibility":"hide"},{"property":"QSi`","visibility":"hide"}],"collection_page_properties":[{"visible":false,"property":"AfoN"},{"visible":true,"property":"BN]P"},{"visible":true,"property":"a\u003cql"},{"visible":false,"property":"}nqi"},{"visible":true,"property":"~]S\u003c"},{"visible":true,"property":"==~K"},{"visible":true,"property":"jhf;"},{"visible":false,"property":"=bhc"},{"visible":false,"property":"NVm^"},{"visible":true,"property":"nAX{"},{"visible":false,"property":";KhU"}]},"parent_id":"4f20ede8-ccf7-4ae1-82e5-819e100dd032","parent_table":"block","alive":true,"copied_from":"e5fdcb8e-6e29-4bc9-828d-263749307808","template_pages":["cacb6437-50cd-4a3d-9d43-58962f75e40b"],"migrated":true,"space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6","deleted_schema":{":nQy":{"name":"Curating","type":"text"}}}}},"collection_view":{"d91647c5-6a81-48b1-a1ff-a04529d0ddba":{"role":"reader","value":{"id":"d91647c5-6a81-48b1-a1ff-a04529d0ddba","version":33,"type":"gallery","name":"Gallery view","format":{"gallery_cover":{"type":"page_cover"},"gallery_cover_size":"medium","gallery_properties":[{"visible":false,"property":"AfoN"},{"visible":false,"property":"jhf;"},{"visible":false,"property":"NVm^"},{"visible":false,"property":"==~K"},{"visible":false,"property":";KhU"},{"visible":false,"property":"=bhc"},{"visible":false,"property":"}nqi"},{"visible":false,"property":"nAX{"},{"visible":false,"property":"BN]P"},{"visible":true,"property":"title"},{"visible":true,"property":"~]S\u003c"},{"visible":true,"property":"a\u003cql"}],"gallery_cover_aspect":"cover","hide_linked_collection_name":true,"inline_collection_first_load_limit":{"type":"load_limit","limit":10}},"parent_id":"4f20ede8-ccf7-4ae1-82e5-819e100dd032","parent_table":"block","alive":true,"page_sort":["e3df5b79-eb34-4bec-a82f-628699f43852","7a8e9c32-39af-4bca-a26e-3f8f1c9a1762","7864e0d8-d646-4df5-a4ae-057371b7559d","36a57bd6-d63a-40f0-a0a2-6ba247885fab","c2994f3d-696a-4015-b7d1-2b71883562ad","58fc3d75-92a2-44e9-ab0d-84cb61086232","30ac6075-b07c-41fa-b684-15c16f1134ba","4c804cac-3119-4cc3-a621-a82040d9a0db","6ce6c0ba-0d6f-40b3-b7d4-afe8ca715c73","64158711-b8f3-4c3d-ba2f-3999059c5581","0c679f04-0865-4142-a65b-28668aa9daea","54fa8c94-ead7-4b14-b068-174936adb37f","ab2e2675-7daf-464f-a2c4-563136630232","ef52bf7e-8726-4804-a0d5-e9b5f7919284","460f888e-b262-4f14-a39f-93ae0090bb9d","eff2e07b-ee44-45e0-b46a-622deb611d0b","c94f3f08-d65f-4f7d-a409-72c353f9786d","daac7673-f388-475e-8f43-a345dc350bef","6ff46924-9cc3-4445-badc-28e7daa5fa5a","c114dc9f-b09a-4e30-9c0d-5ace92e6a8e3","51b78f8b-69ff-4a46-9ec6-74f0d5400d3e","06adcb1d-3acf-4266-a8d9-6cb0d3c439ce","22c49483-380f-4b94-be90-b437b7cbab52","45a3d677-b3df-4cc1-ac40-7e0ab214aeef","7a177274-38ce-4f03-b3f6-06e20b0ba4f8","15aa9135-7cca-40c7-b656-ba4457524924","599373d0-99e2-4c28-89de-d273b43aca5c","48756e2f-e604-4421-9b34-be2c90e20589","b94b3e79-f161-45a8-bf8e-5315f85dca99","3e71fe2e-c827-4fc6-b610-7d71147ae4a7","298f8e1a-a9f2-4274-b5f1-7279f7bc4e5b","c7f629b2-6f4e-43fe-8720-4a3a10d4e651","b1fded7b-ceea-46d0-89e2-32010807d35c","bd99ffd5-ce6d-4418-be0e-6db2cd8ae070","5e852682-71e3-45b9-8056-d40e972563fd","1db23f4a-8d7e-4445-b241-a8e4be5bd02a","70df362d-5c3a-4d2c-a3da-ef27e1f207e3","dae737f3-5216-4c50-b708-2bf7c2662020","a13c9d7e-5e2f-44c3-bd8c-17fd50ca4892","f3236b1d-73c7-45d5-920e-f7cac8c19573","c181e327-c3bf-42f8-b8aa-21a367ce64f2","f5613c52-6b68-4073-b593-03d26f51e710"],"query2":{"sort":[{"property":"=bhc","direction":"descending"},{"property":"a\u003cql","direction":"descending"}],"filter":{"filters":[{"filters":[{"filter":{"value":{"type":"exact","value":true},"operator":"checkbox_is"},"property":"==~K"},{"filter":{"value":{"type":"exact","value":true},"operator":"checkbox_is"},"property":"=bhc"},{"filter":{"value":{"type":"exact","value":true},"operator":"checkbox_is"},"property":"QSi`"}],"operator":"and"}],"operator":"and"},"aggregations":[{"aggregator":"count"}]},"space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}},"27bc73a3-5779-44e0-b617-2f0d26f5aa2f":{"role":"reader","value":{"id":"27bc73a3-5779-44e0-b617-2f0d26f5aa2f","version":1,"type":"table","name":"","format":{"table_properties":[{"width":293,"visible":true,"property":"title"},{"width":398,"visible":true,"property":"~]S\u003c"},{"width":81,"visible":true,"property":"==~K"},{"width":105,"visible":true,"property":"=bhc"},{"width":146,"visible":true,"property":"a\u003cql"},{"width":200,"visible":true,"property":"BN]P"},{"width":122,"visible":true,"property":"}nqi"},{"width":156,"visible":true,"property":"jhf;"},{"width":146,"visible":true,"property":"NVm^"},{"width":200,"visible":true,"property":";KhU"},{"width":200,"visible":false,"property":"nAX{"}]},"parent_id":"4f20ede8-ccf7-4ae1-82e5-819e100dd032","parent_table":"block","alive":true,"page_sort":["f3d44d4c-975d-4b11-8396-c68b35bfdb26","70df362d-5c3a-4d2c-a3da-ef27e1f207e3","f3236b1d-73c7-45d5-920e-f7cac8c19573","4117e62e-18ec-4503-a32a-6c31806a5e2a","6b9736df-63cb-4e7c-ba8e-d6e54f26d6c9","c2f261a2-c616-4198-b1a9-2caf6be162a0","a082287f-d4c9-4cfb-b3b2-72b8bbf043c6","4801bc76-a763-46a8-981d-79dc38c5d85a","e3df5b79-eb34-4bec-a82f-628699f43852","36a57bd6-d63a-40f0-a0a2-6ba247885fab","c2994f3d-696a-4015-b7d1-2b71883562ad","58fc3d75-92a2-44e9-ab0d-84cb61086232","30ac6075-b07c-41fa-b684-15c16f1134ba","4c804cac-3119-4cc3-a621-a82040d9a0db","6ce6c0ba-0d6f-40b3-b7d4-afe8ca715c73","64158711-b8f3-4c3d-ba2f-3999059c5581","0c679f04-0865-4142-a65b-28668aa9daea","54fa8c94-ead7-4b14-b068-174936adb37f","ab2e2675-7daf-464f-a2c4-563136630232","ef52bf7e-8726-4804-a0d5-e9b5f7919284","460f888e-b262-4f14-a39f-93ae0090bb9d","eff2e07b-ee44-45e0-b46a-622deb611d0b","c94f3f08-d65f-4f7d-a409-72c353f9786d","daac7673-f388-475e-8f43-a345dc350bef","6ff46924-9cc3-4445-badc-28e7daa5fa5a","c114dc9f-b09a-4e30-9c0d-5ace92e6a8e3","51b78f8b-69ff-4a46-9ec6-74f0d5400d3e","06adcb1d-3acf-4266-a8d9-6cb0d3c439ce","22c49483-380f-4b94-be90-b437b7cbab52","1db23f4a-8d7e-4445-b241-a8e4be5bd02a","dae737f3-5216-4c50-b708-2bf7c2662020","a13c9d7e-5e2f-44c3-bd8c-17fd50ca4892","7864e0d8-d646-4df5-a4ae-057371b7559d","7a8e9c32-39af-4bca-a26e-3f8f1c9a1762","0f58fdf7-da3e-4793-93f8-b2503443020d","ca43f24a-f6c2-4611-a92a-8051ec80fb0f","36b681a4-e13e-4a78-a2d6-f56b2e3657a1","8cfc0d5a-59ba-4ea0-9609-4720753d5fba","88891af2-1639-4eff-a2c9-f3ba6668b2ea","92db0a94-6e1e-44a6-8df5-882e60ff5b3f","0d958b63-df7a-44a4-b80c-5408c78f59e4","7a177274-38ce-4f03-b3f6-06e20b0ba4f8","ae0b3ee0-531c-4f81-8d4b-cc6dd040fea1","bf9953ee-2589-4969-948c-0d31106a9deb","fdb7d90f-a355-4e7d-8f9a-3d07a58a457e","561e9779-b56c-4310-8913-d54675e02c74","6951e99b-10cc-4833-a27f-f0e08f8941d0","76a4bb7d-be00-45f3-bbcd-cba28c38588b","18c92268-31e5-4509-8644-9c6ad9e44c10","6463af62-efa9-47dc-91ce-99df728f66e0"],"query2":{"sort":[{"property":"=bhc","direction":"descending"},{"property":"a\u003cql","direction":"descending"}],"aggregations":[{"property":"title","aggregator":"count"}]},"space_id":"4af10338-3e65-4b50-af9f-798d59d5c8f6"}}},"notion_user":{},"collection_query":{},"signed_urls":{},"preview_images":{"images.unsplash.com/photo-1563209259-b2fa97148ce1":{"originalWidth":4509,"originalHeight":3433,"dataURIBase64":"data:image/webp;base64,UklGRkQAAABXRUJQVlA4IDgAAAAQAgCdASoQAAwABUB8JZQCdAEN4Z4/0jgAAP7nI6g5q7g7NuXgHKw945x+RhNJbTW2vaRJ2E2wAA=="},"notion.so/image/notion.so%2Fimages%2Fpage-cover%2Fnasa_reduced_gravity_walking_simulator.jpg":{"originalWidth":2000,"originalHeight":1597,"dataURIBase64":"data:image/webp;base64,UklGRjwAAABXRUJQVlA4IDAAAADQAQCdASoQAA0ABUB8JaQAAuUwaXLIHAD+3O9cAAKxBQKBBYBng9tx6GTwHd24mAA="},"notion.so/image/s3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb29e9b03-c79c-4e52-a45e-7228163ba524%2Fcompass-circular-tool_(3).png":{"originalWidth":2000,"originalHeight":2000,"dataURIBase64":"data:image/webp;base64,UklGRv4AAABXRUJQVlA4WAoAAAAQAAAADwAADwAAQUxQSFUAAAARL6CmkRQ4eF5eaio0EBGB5+2AUWxbbR5t/yWkKiDsUwVQnn8xoViI6P8EAOK9AiCF/BQQSXKHsKrOmo21PddC4xsKsbafNSc1jfQLgBSSGsD0HBoAAFZQOCCCAAAAsAIAnQEqEAAQAAVAfCWkAA+DSIAfdDvk/UudpKAAAPYcuQdG3VZft4V447Ryb0FWml/BLapzhboSZ6SLFp2WFSojeqJNq2VAANIrwpK47u1M/geoV8ECX9+TEWBDeQC4c2g3HcSldGi6FylcOf6PWeqJaegO6jdPFlsvX04FC2gAAA=="},"notion.so/image/longshiine.github.io%2F2021%2F01%2F19%2FReinforcement-Learning-Intro%2Flearning.png":{"originalWidth":2000,"originalHeight":1437,"dataURIBase64":"data:image/webp;base64,UklGRmQAAABXRUJQVlA4IFgAAAAwAgCdASoQAAsABUB8JbACdDiMwP18E8JcwAD+8eBmkpSrFZsN3Tv2PDn63bgnxdVShREgdU+8OEyvs8HnWtAFYfZ7ETZhp2ARptd18NZPUtXjo0IjowAA"},"notion.so/image/longshiine.github.io%2F2021%2F01%2F19%2FReinforcement-Learning-Intro%2Fagent.png":{"originalWidth":2000,"originalHeight":796,"dataURIBase64":"data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAADwAQCdASoQAAYABUB8JbAAAxU/hK+OgYAA/usWk5kxNkQhp8kUZ3p6QSN3VyFtHXc4Z/ij8047CJaVylfx4Z1HWszAAA=="},"notion.so/image/longshiine.github.io%2F2021%2F01%2F19%2FReinforcement-Learning-Intro%2Fgame.png":{"originalWidth":2000,"originalHeight":1503,"dataURIBase64":"data:image/webp;base64,UklGRlAAAABXRUJQVlA4IEQAAAAwAgCdASoQAAwABUB8JYgC7DBAAZCFmlGoAAD+CZMoU2eJqSxc/jMOYE9WFevOV+qmaSqXmdRenAgcVTZE7yALpygAAA=="},"notion.so/image/longshiine.github.io%2F2021%2F01%2F19%2FReinforcement-Learning-Intro%2Fbreakout.jpg":{"originalWidth":2000,"originalHeight":2625,"dataURIBase64":"data:image/webp;base64,UklGRlYAAABXRUJQVlA4IEoAAAAQAgCdASoMABAABUB8JaACdEf/gegjQMzMAP7Zq+ufJmGVaXN5ZFKy+H1STmwtChsvxB74q6JtZA+fDMK7KJYaOT/c+JYjDzsAAA=="},"notion.so/image/longshiine.github.io%2F2021%2F01%2F19%2FReinforcement-Learning-Intro%2FDQN.png":{"originalWidth":2000,"originalHeight":890,"dataURIBase64":"data:image/webp;base64,UklGRkgAAABXRUJQVlA4IDwAAACwAQCdASoQAAcABUB8JaQAApQdbsHwAPlz5EUPq+WIXENeBw/kh9Xa7C7cYO0DxtpfLpbw8y5UrysAAAA="},"notion.so/image/s3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffc853118-df50-43ed-96d9-0711493d5e25%2Fjang_inspiration_logo.png":{"originalWidth":2000,"originalHeight":2000,"dataURIBase64":"data:image/webp;base64,UklGRv4AAABXRUJQVlA4WAoAAAAQAAAADwAADwAAQUxQSFUAAAARL6CmkRQ4eF5eaio0EBGB5+2AUWxbbR5t/yWkKiDsUwVQnn8xoViI6P8EAOK9AiCF/BQQSXKHsKrOmo21PddC4xsKsbafNSc1jfQLgBSSGsD0HBoAAFZQOCCCAAAAsAIAnQEqEAAQAAVAfCWkAA+DSIAfdDvk/UudpKAAAPYcuQdG3VZft4V447Ryb0FWml/BLapzhboSZ6SLFp2WFSojeqJNq2VAANIrwpK47u1M/geoV8ECX9+TEWBDeQC4c2g3HcSldGi6FylcOf6PWeqJaegO6jdPFlsvX04FC2gAAA=="}}},"pageId":"3fd51011-fdfe-4366-931c-6ed584049b34","rawPageId":"1"},"__N_SSG":true},"page":"/[pageId]","query":{"pageId":"1"},"buildId":"I-ojLq_lc7g-_5LzXbOVe","isFallback":false,"dynamicIds":[635],"gsp":true,"scriptLoader":[]}</script></body></html>